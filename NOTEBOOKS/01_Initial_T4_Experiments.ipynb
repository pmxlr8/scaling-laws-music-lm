{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"McSD3hx0m7wy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":96954,"status":"ok","timestamp":1765527105468,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"},"user_tz":300},"id":"9Ri1e8YbB_Nt","outputId":"8a153372-599f-4baf-b660-e3a53b19764f"},"outputs":[{"name":"stdout","output_type":"stream","text":["üõ†Ô∏è  Step 1: Installing Dependencies...\n","Mounted at /content/drive\n","üì¶ Extracting Tarball to Local Disk (Fast I/O)...\n","‚úÖ Extraction Complete.\n"]}],"source":["# ==========================================\n","# BLOCK 1: ENVIRONMENT & EXTRACTION\n","# ==========================================\n","import os\n","import shutil\n","import subprocess\n","import sys\n","from pathlib import Path\n","from google.colab import drive\n","\n","print(\"üõ†Ô∏è  Step 1: Installing Dependencies...\")\n","subprocess.run(\"apt-get update -qq && apt-get install -y abcmidi\", shell=True, check=False)\n","subprocess.run(\"pip install -q tokenizers regex tqdm scipy matplotlib\", shell=True, check=False)\n","\n","# Mount Drive\n","drive.mount('/content/drive')\n","\n","# PATHS\n","DRIVE_BASE = '/content/drive/MyDrive/NYU_ML_Project'\n","DRIVE_TAR = f'{DRIVE_BASE}/Data/lmd_full.tar.gz'\n","# If tarball is missing, try to find it\n","if not os.path.exists(DRIVE_TAR):\n","    found = list(Path('/content/drive').rglob('lmd_full.tar.gz'))\n","    if found: DRIVE_TAR = str(found[0])\n","\n","LOCAL_BASE = '/content/music_project'\n","LOCAL_MIDI = f'{LOCAL_BASE}/midi'\n","LOCAL_ABC = f'{LOCAL_BASE}/abc'\n","LOCAL_PROCESSED = f'{LOCAL_BASE}/processed'\n","\n","# Create Directories\n","for d in [LOCAL_MIDI, LOCAL_ABC, LOCAL_PROCESSED]:\n","    os.makedirs(d, exist_ok=True)\n","\n","# INTELLIGENT RECOVERY: Skip extraction if files exist\n","abc_count = len(list(Path(LOCAL_ABC).glob(\"*.abc\")))\n","if abc_count > 1000:\n","    print(f\"‚úÖ Found {abc_count:,} existing ABC files. Skipping extraction.\")\n","else:\n","    print(f\"üì¶ Extracting Tarball to Local Disk (Fast I/O)...\")\n","    if not os.path.exists(DRIVE_TAR):\n","        print(f\"‚ùå CRITICAL: Could not find lmd_full.tar.gz in Drive.\")\n","    else:\n","        # Extract to temp then move to ensure flat structure\n","        subprocess.run(['tar', '-xzf', DRIVE_TAR, '-C', LOCAL_MIDI], check=True)\n","        print(\"‚úÖ Extraction Complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9364150,"status":"ok","timestamp":1765536479842,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"},"user_tz":300},"id":"ORjmp6-RnTd_","outputId":"707271d7-6983-4d7c-dcf2-e9b18e3fb8c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["üéµ Converting MIDI -> ABC...\n"]},{"name":"stderr","output_type":"stream","text":["Converting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178561/178561 [02:09<00:00, 1374.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["üßπ Cleaning & Deduplicating...\n"]},{"name":"stderr","output_type":"stream","text":["Cleaning: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178561/178561 [05:37<00:00, 529.61it/s] \n"]},{"name":"stdout","output_type":"stream","text":["üß† Training Tokenizer...\n","üî¢ Encoding Binary...\n"]},{"name":"stderr","output_type":"stream","text":["Encoding: 1146230100it [2:02:44, 155637.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["‚úÇÔ∏è  Splitting 8,365,203,917 tokens...\n","‚úÖ Data Pipeline Complete & Backed Up.\n"]}],"source":["# ==========================================\n","# BLOCK 2: BATCH PROCESSING\n","# ==========================================\n","import hashlib\n","import pickle\n","import numpy as np\n","from tqdm import tqdm\n","from concurrent.futures import ProcessPoolExecutor\n","from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n","\n","# 1. MIDI -> ABC (Parallel)\n","# Only run if ABC folder is empty\n","if len(list(Path(LOCAL_ABC).glob(\"*.abc\"))) < 100:\n","    print(\"üéµ Converting MIDI -> ABC...\")\n","    midi_files = list(Path(LOCAL_MIDI).rglob(\"*.mid\")) + list(Path(LOCAL_MIDI).rglob(\"*.midi\"))\n","\n","    def convert(path):\n","        try:\n","            h = hashlib.md5(str(path).encode()).hexdigest()\n","            out = f\"{LOCAL_ABC}/{h}.abc\"\n","            # 10s timeout prevents hanging on bad files\n","            subprocess.run(['midi2abc', str(path), '-o', out], capture_output=True, timeout=10)\n","            return 1\n","        except: return 0\n","\n","    with ProcessPoolExecutor() as exe:\n","        list(tqdm(exe.map(convert, midi_files), total=len(midi_files), desc=\"Converting\"))\n","\n","# 2. CLEAN & DEDUP (Stream to file)\n","clean_path = f'{LOCAL_PROCESSED}/clean_corpus.txt'\n","if not os.path.exists(clean_path):\n","    print(\"üßπ Cleaning & Deduplicating...\")\n","    seen = set()\n","    files = list(Path(LOCAL_ABC).glob(\"*.abc\"))\n","    with open(clean_path, 'w') as f_out:\n","        for p in tqdm(files, desc=\"Cleaning\"):\n","            try:\n","                # header check\n","                with open(p, 'r', errors='ignore') as f:\n","                    head = f.read(50)\n","                    if \"X:\" not in head: continue\n","\n","                text = p.read_text(errors='ignore')\n","                h = hashlib.md5(text.strip().encode()).hexdigest()\n","                if h in seen: continue\n","                seen.add(h)\n","\n","                lines = [l for l in text.splitlines() if not l.startswith('%')]\n","                f_out.write('\\n'.join(lines) + \"\\n<|endoftext|>\\n\")\n","            except: continue\n","\n","# 3. TRAIN TOKENIZER\n","tok_path = f'{LOCAL_PROCESSED}/music_bpe.json'\n","print(\"üß† Training Tokenizer...\")\n","tok = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n","tok.pre_tokenizer = pre_tokenizers.Whitespace()\n","trainer = trainers.BpeTrainer(vocab_size=5000, special_tokens=[\"<|endoftext|>\", \"<unk>\", \"<pad>\"])\n","tok.train([clean_path], trainer)\n","tok.save(tok_path)\n","\n","# 4. BATCH BINARY ENCODING (Speed + Safety)\n","print(\"üî¢ Encoding Binary...\")\n","all_bin = f'{LOCAL_PROCESSED}/all.bin'\n","BATCH_SIZE = 20000\n","total_tokens = 0\n","\n","if not os.path.exists(all_bin):\n","    with open(clean_path, 'r') as f_in, open(all_bin, 'wb') as f_out:\n","        batch = []\n","        for line in tqdm(f_in, desc=\"Encoding\"):\n","            if not line.strip(): continue\n","            batch.append(line)\n","            if len(batch) >= BATCH_SIZE:\n","                # Fast C++ encoding\n","                encs = tok.encode_batch(batch)\n","                for e in encs:\n","                    f_out.write(np.array(e.ids, dtype=np.uint16).tobytes())\n","                    total_tokens += len(e.ids)\n","                batch = []\n","        if batch:\n","            encs = tok.encode_batch(batch)\n","            for e in encs:\n","                f_out.write(np.array(e.ids, dtype=np.uint16).tobytes())\n","                total_tokens += len(e.ids)\n","else:\n","    total_tokens = os.path.getsize(all_bin) // 2\n","\n","# 5. SPLIT & SAVE\n","print(f\"‚úÇÔ∏è  Splitting {total_tokens:,} tokens...\")\n","n_train = int(total_tokens * 0.98)\n","n_val = int(total_tokens * 0.01)\n","\n","data = np.memmap(all_bin, dtype=np.uint16, mode='r')\n","with open(f'{LOCAL_PROCESSED}/train.bin', 'wb') as f: f.write(data[:n_train].tobytes())\n","with open(f'{LOCAL_PROCESSED}/val.bin', 'wb') as f: f.write(data[n_train:n_train+n_val].tobytes())\n","with open(f'{LOCAL_PROCESSED}/test.bin', 'wb') as f: f.write(data[n_train+n_val:].tobytes())\n","\n","meta = {'vocab_size': 5000, 'train_tokens': n_train}\n","with open(f'{LOCAL_PROCESSED}/meta.pkl', 'wb') as f: pickle.dump(meta, f)\n","\n","# Backup to Drive\n","DRIVE_PROCESSED = f'{DRIVE_BASE}/Data/processed_v4'\n","if os.path.exists(DRIVE_PROCESSED): shutil.rmtree(DRIVE_PROCESSED)\n","shutil.copytree(LOCAL_PROCESSED, DRIVE_PROCESSED)\n","print(\"‚úÖ Data Pipeline Complete & Backed Up.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbvG7yHOnkm3"},"outputs":[],"source":["# ==========================================\n","# BLOCK 3: CAUSAL MODEL DEFINITIONS\n","# ==========================================\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dataclasses import dataclass\n","\n","@dataclass\n","class GPTConfig:\n","    vocab_size: int = 5000\n","    n_layer: int = 12\n","    n_head: int = 12\n","    n_embd: int = 768\n","    block_size: int = 256\n","    dropout: float = 0.1\n","\n","class CausalSelfAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        assert config.n_embd % config.n_head == 0\n","        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n","        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n","        self.attn_dropout = nn.Dropout(config.dropout)\n","        self.resid_dropout = nn.Dropout(config.dropout)\n","        self.n_head = config.n_head\n","        self.n_embd = config.n_embd\n","        # The Mask is Critical\n","        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n","                                     .view(1, 1, config.block_size, config.block_size))\n","\n","    def forward(self, x):\n","        B, T, C = x.size()\n","        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n","\n","        att = (q @ k.transpose(-2, -1)) * (1.0 / (k.size(-1)**0.5))\n","        # Enforce Causality\n","        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_dropout(att)\n","        y = att @ v\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","        return self.resid_dropout(self.c_proj(y))\n","\n","class Block(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.ln_1 = nn.LayerNorm(config.n_embd)\n","        self.attn = CausalSelfAttention(config)\n","        self.ln_2 = nn.LayerNorm(config.n_embd)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(config.n_embd, 4 * config.n_embd),\n","            nn.GELU(),\n","            nn.Linear(4 * config.n_embd, config.n_embd),\n","            nn.Dropout(config.dropout),\n","        )\n","    def forward(self, x):\n","        x = x + self.attn(self.ln_1(x))\n","        x = x + self.mlp(self.ln_2(x))\n","        return x\n","\n","class GPT(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n","        self.pos_emb = nn.Embedding(config.block_size, config.n_embd)\n","        self.drop = nn.Dropout(config.dropout)\n","        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n","        self.ln_f = nn.LayerNorm(config.n_embd)\n","        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n","        self.block_size = config.block_size\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.size()\n","        pos = torch.arange(0, T, device=idx.device)\n","        x = self.tok_emb(idx) + self.pos_emb(pos)\n","        x = self.drop(x)\n","        for block in self.blocks: x = block(x)\n","        x = self.ln_f(x)\n","        logits = self.head(x)\n","        loss = None\n","        if targets is not None:\n","            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n","        return logits, loss\n","\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_size, embed_dim)\n","        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","    def forward(self, idx, targets=None):\n","        x = self.emb(idx)\n","        x, _ = self.lstm(x)\n","        logits = self.fc(x)\n","        loss = None\n","        if targets is not None:\n","            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n","        return logits, loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"executionInfo":{"elapsed":11,"status":"error","timestamp":1765555619846,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"},"user_tz":300},"id":"S-2fxkmmnn8a","outputId":"0fe69c89-dd11-424a-efdb-09683c479709"},"outputs":[{"ename":"NameError","evalue":"name 'DRIVE_BASE' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1521654936.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# BLOCK 4: TRAINING ENGINE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ==========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mDRIVE_CHECKPOINTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{DRIVE_BASE}/checkpoints_v4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mDRIVE_RESULTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{DRIVE_BASE}/results_v4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDRIVE_CHECKPOINTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'DRIVE_BASE' is not defined"]}],"source":["# ==========================================\n","# BLOCK 4: TRAINING ENGINE\n","# ==========================================\n","DRIVE_CHECKPOINTS = f'{DRIVE_BASE}/checkpoints_v4'\n","DRIVE_RESULTS = f'{DRIVE_BASE}/results_v4'\n","os.makedirs(DRIVE_CHECKPOINTS, exist_ok=True)\n","os.makedirs(DRIVE_RESULTS, exist_ok=True)\n","\n","class DataLoader:\n","    def __init__(self, path, batch_size=32, block_size=256):\n","        self.data = np.memmap(path, dtype=np.uint16, mode='r')\n","        self.bs = batch_size\n","        self.bl = block_size\n","    def get_batch(self):\n","        ix = torch.randint(len(self.data) - self.bl, (self.bs,))\n","        x = torch.stack([torch.from_numpy((self.data[i:i+self.bl]).astype(np.int64)) for i in ix])\n","        y = torch.stack([torch.from_numpy((self.data[i+1:i+1+self.bl]).astype(np.int64)) for i in ix])\n","        return x, y\n","\n","def get_lr(step, max_steps, base_lr):\n","    warmup = 500\n","    if step < warmup: return base_lr * (step + 1) / warmup\n","    progress = (step - warmup) / (max_steps - warmup)\n","    return base_lr * 0.5 * (1.0 + math.cos(math.pi * progress))\n","\n","def train_model(config, name, type, steps):\n","    device = 'cuda'\n","    if type == 'gpt':\n","        model = GPT(GPTConfig(n_layer=config['n_layer'], n_embd=config['n_embd'], n_head=config['n_head']))\n","    else:\n","        model = LSTM(5000, config['hidden'], config['hidden'], config['layers'])\n","    model.to(device)\n","\n","    # Weight decay fix\n","    param_dict = {pn: p for pn, p in model.named_parameters() if p.requires_grad}\n","    decay = [p for n, p in param_dict.items() if p.dim() >= 2]\n","    nodecay = [p for n, p in param_dict.items() if p.dim() < 2]\n","    optim = torch.optim.AdamW([{'params':decay, 'weight_decay':config['wd']},\n","                               {'params':nodecay, 'weight_decay':0.0}], lr=config['lr'])\n","\n","    train_loader = DataLoader(f'{LOCAL_PROCESSED}/train.bin')\n","    val_loader = DataLoader(f'{LOCAL_PROCESSED}/val.bin')\n","\n","    ckpt_path = f\"{DRIVE_CHECKPOINTS}/{name}.pt\"\n","    start_step = 0\n","    if os.path.exists(ckpt_path):\n","        state = torch.load(ckpt_path)\n","        model.load_state_dict(state['model'])\n","        optim.load_state_dict(state['optim'])\n","        start_step = state['step']\n","        print(f\"   ‚è© Resuming {name} from step {start_step}\")\n","\n","    model.train()\n","    pbar = tqdm(range(start_step, steps), desc=name)\n","    val_loss = 0.0\n","\n","    for step in pbar:\n","        lr = get_lr(step, steps, config['lr'])\n","        for g in optim.param_groups: g['lr'] = lr\n","\n","        x, y = train_loader.get_batch()\n","        x, y = x.to(device), y.to(device)\n","        _, loss = model(x, y)\n","\n","        optim.zero_grad(); loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0); optim.step()\n","\n","        if (step + 1) % 1000 == 0 or step == steps - 1:\n","            model.eval()\n","            with torch.no_grad():\n","                xv, yv = val_loader.get_batch()\n","                xv, yv = xv.to(device), yv.to(device)\n","                _, val_loss = model(xv, yv)\n","            model.train()\n","            torch.save({'model': model.state_dict(), 'optim':optim.state_dict(), 'step': step+1, 'val_loss': val_loss.item()}, ckpt_path)\n","            pbar.set_postfix(loss=f\"{loss.item():.4f}\", val=f\"{val_loss.item():.4f}\")\n","\n","    return val_loss.item(), sum(p.numel() for p in model.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"executionInfo":{"elapsed":48626,"status":"error","timestamp":1765536533544,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"},"user_tz":300},"id":"ntNBKrtZn3fN","outputId":"4859302d-72e5-47a7-d0d7-ce69a06683ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["‚ÑπÔ∏è  1 Epoch = 1,000,720 steps\n","üöÄ Training gpt_tiny...\n"]},{"name":"stderr","output_type":"stream","text":["gpt_tiny:   0%|          | 500/1000720 [00:42<23:35:17, 11.78it/s]\n"]},{"ename":"NameError","evalue":"name 'math' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4263625939.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üöÄ Training {exp['name']}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1521654936.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(config, name, type, steps)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1521654936.py\u001b[0m in \u001b[0;36mget_lr\u001b[0;34m(step, max_steps, base_lr)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbase_lr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_lr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"]}],"source":["# ==========================================\n","# BLOCK 5: EXECUTION, TEST & PLOTS\n","# ==========================================\n","import pickle\n","with open(f'{LOCAL_PROCESSED}/meta.pkl', 'rb') as f:\n","    meta = pickle.load(f)\n","    STEPS = meta['train_tokens'] // (32 * 256)\n","\n","print(f\"‚ÑπÔ∏è  1 Epoch = {STEPS:,} steps\")\n","\n","experiments = [\n","    # 5 GPTs (Adaptive LR + Dropout)\n","    {'name': 'gpt_tiny',   'type': 'gpt', 'n_layer': 2,  'n_embd': 128, 'n_head': 4,  'lr': 1e-3, 'wd': 0.01},\n","    {'name': 'gpt_small',  'type': 'gpt', 'n_layer': 4,  'n_embd': 256, 'n_head': 4,  'lr': 6e-4, 'wd': 0.01},\n","    {'name': 'gpt_medium', 'type': 'gpt', 'n_layer': 6,  'n_embd': 384, 'n_head': 6,  'lr': 3e-4, 'wd': 0.1},\n","    {'name': 'gpt_large',  'type': 'gpt', 'n_layer': 12, 'n_embd': 576, 'n_head': 8,  'lr': 2e-4, 'wd': 0.1},\n","    {'name': 'gpt_xl',     'type': 'gpt', 'n_layer': 16, 'n_embd': 768, 'n_head': 12, 'lr': 1e-4, 'wd': 0.1},\n","    # 4 LSTMs (Matched sizes)\n","    {'name': 'lstm_small', 'type': 'lstm', 'layers': 2, 'hidden': 256, 'lr': 1e-3, 'wd': 0.0},\n","    {'name': 'lstm_med',   'type': 'lstm', 'layers': 2, 'hidden': 512, 'lr': 6e-4, 'wd': 0.0},\n","    {'name': 'lstm_large', 'type': 'lstm', 'layers': 3, 'hidden': 800, 'lr': 3e-4, 'wd': 0.0},\n","    {'name': 'lstm_xl',    'type': 'lstm', 'layers': 4, 'hidden': 1200, 'lr': 1e-4, 'wd': 0.0}\n","]\n","\n","results = {}\n","res_path = f'{DRIVE_RESULTS}/final_results.pkl'\n","if os.path.exists(res_path):\n","    with open(res_path, 'rb') as f: results = pickle.load(f)\n","\n","# Train\n","for exp in experiments:\n","    if exp['name'] in results: continue\n","    print(f\"üöÄ Training {exp['name']}...\")\n","    loss, params = train_model(exp, exp['name'], exp['type'], STEPS)\n","    results[exp['name']] = {'loss': loss, 'params': params, 'type': exp['type']}\n","    with open(res_path, 'wb') as f: pickle.dump(results, f)\n","\n","# TEST SET EVALUATION\n","print(\"\\nüìä Calculating Test Set Metrics...\")\n","test_loader = DataLoader(f'{LOCAL_PROCESSED}/test.bin')\n","best_name = min(results, key=lambda k: results[k]['loss'])\n","cfg = next(e for e in experiments if e['name'] == best_name)\n","\n","if cfg['type']=='gpt': model = GPT(GPTConfig(n_layer=cfg['n_layer'], n_embd=cfg['n_embd'], n_head=cfg['n_head']))\n","else: model = LSTM(5000, cfg['hidden'], cfg['hidden'], cfg['layers'])\n","\n","model.load_state_dict(torch.load(f\"{DRIVE_CHECKPOINTS}/{best_name}.pt\")['model'])\n","model.to('cuda').eval()\n","\n","total_nll = 0\n","count = 0\n","for _ in range(50): # Sample 50 batches\n","    x, y = test_loader.get_batch()\n","    with torch.no_grad():\n","        _, loss = model(x.to('cuda'), y.to('cuda'))\n","        total_nll += loss.item()\n","        count += 1\n","print(f\"üèÜ Best Model: {best_name}\")\n","print(f\"üìâ Test Perplexity: {math.exp(total_nll/count):.2f}\")\n","\n","# PLOTS\n","import matplotlib.pyplot as plt\n","from scipy.optimize import curve_fit\n","gpt_x = sorted([v['params'] for v in results.values() if v['type']=='gpt'])\n","gpt_y = sorted([v['loss'] for v in results.values() if v['type']=='gpt'])\n","lstm_x = sorted([v['params'] for v in results.values() if v['type']=='lstm'])\n","lstm_y = sorted([v['loss'] for v in results.values() if v['type']=='lstm'])\n","\n","plt.figure(figsize=(10,6))\n","if gpt_x:\n","    plt.scatter(gpt_x, gpt_y, c='blue', label='GPT')\n","    try:\n","        popt, _ = curve_fit(lambda x, a, b, c: a * x**(-b) + c, gpt_x, gpt_y, p0=[1, 0.1, 0.5])\n","        plt.plot(gpt_x, popt[0]*np.array(gpt_x)**(-popt[1]) + popt[2], 'b--', label=f'Fit alpha={popt[1]:.2f}')\n","    except: pass\n","if lstm_x: plt.scatter(lstm_x, lstm_y, c='red', marker='x', label='LSTM')\n","plt.xscale('log'); plt.yscale('log'); plt.legend(); plt.grid(True)\n","plt.savefig(f'{DRIVE_RESULTS}/scaling.png')\n","\n","# GENERATION\n","print(\"üéπ Generating 12 Samples...\")\n","tok = Tokenizer.from_file(f'{LOCAL_PROCESSED}/music_bpe.json')\n","def generate():\n","    ids = torch.tensor([tok.encode(\"X:1\\n\").ids]).to('cuda')\n","    for _ in range(512):\n","        logits = model(ids[:, -256:])[0][:, -1, :]\n","        probs = F.softmax(logits, dim=-1)\n","        # Nucleus Sampling (Top-P)\n","        sorted_probs, indices = torch.sort(probs, descending=True)\n","        cumsum = torch.cumsum(sorted_probs, dim=-1)\n","        remove = cumsum > 0.9\n","        remove[..., 1:] = remove[..., :-1].clone(); remove[..., 0] = 0\n","        logits[0, indices[0, remove[0]]] = -float('inf')\n","        next_id = torch.multinomial(F.softmax(logits, dim=-1), 1)\n","        ids = torch.cat((ids, next_id), dim=1)\n","        if next_id.item() == tok.token_to_id(\"<|endoftext|>\"): break\n","    return tok.decode(ids[0].tolist())\n","\n","for i in range(12):\n","    path = f'{DRIVE_RESULTS}/sample_{i}'\n","    with open(f'{path}.abc', 'w') as f: f.write(generate())\n","    subprocess.run(['abc2midi', f'{path}.abc', '-o', f'{path}.mid'], check=False)\n","\n","print(\"‚úÖ PROJECT COMPLETE.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":630},"executionInfo":{"elapsed":1483055,"status":"error","timestamp":1765557637017,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"},"user_tz":300},"id":"Ph3fuUXXn4sI","outputId":"ada4372b-85a2-4891-a5a7-1fbecec1b9e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["üõ†Ô∏è  Initializing Training Environment...\n","Mounted at /content/drive\n","üì• Restoring processed data from /content/drive/MyDrive/NYU_ML_Project/Data/processed_v4...\n","‚úÖ Data Restored to Local Disk.\n","‚ÑπÔ∏è  Vocab: 5000, Steps/Epoch: 1,000,720\n","\n","üöÄ Starting Training Loop...\n","\n","‚ñ∂Ô∏è  Training gpt_tiny...\n"]},{"name":"stderr","output_type":"stream","text":["gpt_tiny:   6%|‚ñå         | 59594/1000720 [20:21<5:21:26, 48.80it/s, loss=0.1796, val=0.2396]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1258560874.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n‚ñ∂Ô∏è  Training {exp['name']}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1258560874.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(config, name, type, steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# ==============================================================================\n","# PHASE 2: TRAINING RECOVERY & EXECUTION\n","# ==============================================================================\n","import os\n","import sys\n","import math  # <--- FIXED: Added missing import\n","import shutil\n","import pickle\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dataclasses import dataclass\n","from tqdm import tqdm\n","from google.colab import drive\n","\n","print(\"üõ†Ô∏è  Initializing Training Environment...\")\n","drive.mount('/content/drive')\n","\n","# --- 1. PATH CONFIGURATION ---\n","# We assume the data pipeline finished and backed up to Drive\n","DRIVE_BASE = '/content/drive/MyDrive/NYU_ML_Project'\n","# Try to find where the data was saved (v4 or final)\n","if os.path.exists(f'{DRIVE_BASE}/Data/processed_final'):\n","    DRIVE_PROCESSED = f'{DRIVE_BASE}/Data/processed_final'\n","elif os.path.exists(f'{DRIVE_BASE}/Data/processed_v4'):\n","    DRIVE_PROCESSED = f'{DRIVE_BASE}/Data/processed_v4'\n","else:\n","    raise FileNotFoundError(\"‚ùå Could not find processed data in Drive! Did the previous step finish backing up?\")\n","\n","DRIVE_CHECKPOINTS = f'{DRIVE_BASE}/checkpoints_final'\n","DRIVE_RESULTS = f'{DRIVE_BASE}/results_final'\n","\n","# Local fast storage\n","LOCAL_PROCESSED = '/content/music_project/processed'\n","os.makedirs(LOCAL_PROCESSED, exist_ok=True)\n","os.makedirs(DRIVE_CHECKPOINTS, exist_ok=True)\n","os.makedirs(DRIVE_RESULTS, exist_ok=True)\n","\n","# --- 2. RESTORE DATA (Drive -> Local) ---\n","# We copy data back to local VM so training is fast (Drive I/O is too slow for training)\n","if not os.path.exists(f'{LOCAL_PROCESSED}/train.bin'):\n","    print(f\"üì• Restoring processed data from {DRIVE_PROCESSED}...\")\n","    try:\n","        shutil.copy(f'{DRIVE_PROCESSED}/train.bin', f'{LOCAL_PROCESSED}/train.bin')\n","        shutil.copy(f'{DRIVE_PROCESSED}/val.bin', f'{LOCAL_PROCESSED}/val.bin')\n","        shutil.copy(f'{DRIVE_PROCESSED}/test.bin', f'{LOCAL_PROCESSED}/test.bin') # Check if exists\n","        shutil.copy(f'{DRIVE_PROCESSED}/meta.pkl', f'{LOCAL_PROCESSED}/meta.pkl')\n","        shutil.copy(f'{DRIVE_PROCESSED}/music_bpe.json', f'{LOCAL_PROCESSED}/music_bpe.json')\n","        print(\"‚úÖ Data Restored to Local Disk.\")\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Minor error restoring files (maybe test.bin missing?): {e}\")\n","\n","# Load Meta\n","with open(f'{LOCAL_PROCESSED}/meta.pkl', 'rb') as f:\n","    meta = pickle.load(f)\n","    VOCAB_SIZE = meta['vocab_size']\n","    # Recalculate steps based on batch size\n","    STEPS_PER_EPOCH = meta['train_tokens'] // (32 * 256)\n","\n","print(f\"‚ÑπÔ∏è  Vocab: {VOCAB_SIZE}, Steps/Epoch: {STEPS_PER_EPOCH:,}\")\n","\n","# --- 3. MODEL ARCHITECTURES ---\n","@dataclass\n","class GPTConfig:\n","    vocab_size: int = VOCAB_SIZE\n","    n_layer: int = 12\n","    n_head: int = 12\n","    n_embd: int = 768\n","    block_size: int = 256\n","    dropout: float = 0.1\n","\n","class CausalSelfAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n","        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n","        self.attn_dropout = nn.Dropout(config.dropout)\n","        self.resid_dropout = nn.Dropout(config.dropout)\n","        self.n_head = config.n_head\n","        self.n_embd = config.n_embd\n","        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n","                                     .view(1, 1, config.block_size, config.block_size))\n","\n","    def forward(self, x):\n","        B, T, C = x.size()\n","        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n","        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_dropout(att)\n","        y = att @ v\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","        return self.resid_dropout(self.c_proj(y))\n","\n","class Block(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.ln_1 = nn.LayerNorm(config.n_embd)\n","        self.attn = CausalSelfAttention(config)\n","        self.ln_2 = nn.LayerNorm(config.n_embd)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(config.n_embd, 4 * config.n_embd),\n","            nn.GELU(),\n","            nn.Linear(4 * config.n_embd, config.n_embd),\n","            nn.Dropout(config.dropout),\n","        )\n","    def forward(self, x):\n","        x = x + self.attn(self.ln_1(x))\n","        x = x + self.mlp(self.ln_2(x))\n","        return x\n","\n","class GPT(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n","        self.pos_emb = nn.Embedding(config.block_size, config.n_embd)\n","        self.drop = nn.Dropout(config.dropout)\n","        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n","        self.ln_f = nn.LayerNorm(config.n_embd)\n","        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n","        self.block_size = config.block_size\n","\n","    def forward(self, idx, targets=None):\n","        device = idx.device\n","        B, T = idx.size()\n","        pos = torch.arange(0, T, device=device)\n","        x = self.tok_emb(idx) + self.pos_emb(pos)\n","        x = self.drop(x)\n","        for block in self.blocks: x = block(x)\n","        x = self.ln_f(x)\n","        logits = self.head(x)\n","        loss = None\n","        if targets is not None:\n","            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n","        return logits, loss\n","\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_size, embed_dim)\n","        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","    def forward(self, idx, targets=None):\n","        x = self.emb(idx)\n","        x, _ = self.lstm(x)\n","        logits = self.fc(x)\n","        loss = None\n","        if targets is not None:\n","            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n","        return logits, loss\n","\n","# --- 4. TRAINING ENGINE ---\n","class DataLoader:\n","    def __init__(self, path, batch_size=32, block_size=256):\n","        self.data = np.memmap(path, dtype=np.uint16, mode='r')\n","        self.bs = batch_size\n","        self.bl = block_size\n","    def get_batch(self):\n","        ix = torch.randint(len(self.data) - self.bl, (self.bs,))\n","        x = torch.stack([torch.from_numpy((self.data[i:i+self.bl]).astype(np.int64)) for i in ix])\n","        y = torch.stack([torch.from_numpy((self.data[i+1:i+1+self.bl]).astype(np.int64)) for i in ix])\n","        return x, y\n","\n","def get_lr(step, max_steps, base_lr):\n","    warmup = 500\n","    if step < warmup: return base_lr * (step + 1) / warmup\n","    progress = (step - warmup) / (max_steps - warmup)\n","    # Cosine decay\n","    return base_lr * 0.5 * (1.0 + math.cos(math.pi * progress))\n","\n","def train_model(config, name, type, steps):\n","    device = 'cuda'\n","    if type == 'gpt':\n","        model = GPT(GPTConfig(n_layer=config['n_layer'], n_embd=config['n_embd'], n_head=config['n_head']))\n","    else:\n","        model = LSTM(VOCAB_SIZE, config['hidden'], config['hidden'], config['layers'])\n","    model.to(device)\n","\n","    param_dict = {pn: p for pn, p in model.named_parameters() if p.requires_grad}\n","    decay = [p for n, p in param_dict.items() if p.dim() >= 2]\n","    nodecay = [p for n, p in param_dict.items() if p.dim() < 2]\n","    optim = torch.optim.AdamW([\n","        {'params': decay, 'weight_decay': config['wd']},\n","        {'params': nodecay, 'weight_decay': 0.0}\n","    ], lr=config['lr'])\n","\n","    train_loader = DataLoader(f'{LOCAL_PROCESSED}/train.bin')\n","    val_loader = DataLoader(f'{LOCAL_PROCESSED}/val.bin')\n","\n","    ckpt_path = f\"{DRIVE_CHECKPOINTS}/{name}.pt\"\n","    start_step = 0\n","\n","    # Resume Logic\n","    if os.path.exists(ckpt_path):\n","        try:\n","            state = torch.load(ckpt_path)\n","            model.load_state_dict(state['model'])\n","            optim.load_state_dict(state['optim'])\n","            start_step = state['step']\n","            print(f\"   ‚è© Resuming {name} from step {start_step}\")\n","        except:\n","            print(\"   ‚ö†Ô∏è Checkpoint corrupted? Starting fresh.\")\n","\n","    model.train()\n","    pbar = tqdm(range(start_step, steps), desc=name)\n","    val_loss = 0.0\n","\n","    for step in pbar:\n","        lr = get_lr(step, steps, config['lr'])\n","        for g in optim.param_groups: g['lr'] = lr\n","\n","        x, y = train_loader.get_batch()\n","        x, y = x.to(device), y.to(device)\n","        _, loss = model(x, y)\n","\n","        optim.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optim.step()\n","\n","        # Validate & Save every 1000 steps\n","        if (step + 1) % 1000 == 0 or step == steps - 1:\n","            model.eval()\n","            with torch.no_grad():\n","                xv, yv = val_loader.get_batch()\n","                xv, yv = xv.to(device), yv.to(device)\n","                _, val_loss = model(xv, yv)\n","            model.train()\n","\n","            torch.save({\n","                'model': model.state_dict(),\n","                'optim': optim.state_dict(),\n","                'step': step+1,\n","                'val_loss': val_loss.item()\n","            }, ckpt_path)\n","\n","            pbar.set_postfix(loss=f\"{loss.item():.4f}\", val=f\"{val_loss.item():.4f}\")\n","\n","    return val_loss.item(), sum(p.numel() for p in model.parameters())\n","\n","# --- 5. EXECUTION ---\n","print(\"\\nüöÄ Starting Training Loop...\")\n","\n","experiments = [\n","    # GPTs\n","    {'name': 'gpt_tiny',   'type': 'gpt', 'n_layer': 2,  'n_embd': 128, 'n_head': 4,  'lr': 1e-3, 'wd': 0.01},\n","    {'name': 'gpt_small',  'type': 'gpt', 'n_layer': 4,  'n_embd': 256, 'n_head': 4,  'lr': 6e-4, 'wd': 0.01},\n","    {'name': 'gpt_medium', 'type': 'gpt', 'n_layer': 6,  'n_embd': 384, 'n_head': 6,  'lr': 3e-4, 'wd': 0.1},\n","    {'name': 'gpt_large',  'type': 'gpt', 'n_layer': 12, 'n_embd': 576, 'n_head': 12, 'lr': 2e-4, 'wd': 0.1},\n","    {'name': 'gpt_xl',     'type': 'gpt', 'n_layer': 16, 'n_embd': 768, 'n_head': 12, 'lr': 1e-4, 'wd': 0.1},\n","    # LSTMs\n","    {'name': 'lstm_small', 'type': 'lstm', 'layers': 2, 'hidden': 256, 'lr': 1e-3, 'wd': 0.0},\n","    {'name': 'lstm_med',   'type': 'lstm', 'layers': 2, 'hidden': 512, 'lr': 6e-4, 'wd': 0.0},\n","    {'name': 'lstm_large', 'type': 'lstm', 'layers': 3, 'hidden': 800, 'lr': 3e-4, 'wd': 0.0},\n","    {'name': 'lstm_xl',    'type': 'lstm', 'layers': 4, 'hidden': 1200, 'lr': 1e-4, 'wd': 0.0}\n","]\n","\n","results = {}\n","res_path = f'{DRIVE_RESULTS}/final_results.pkl'\n","if os.path.exists(res_path):\n","    with open(res_path, 'rb') as f: results = pickle.load(f)\n","\n","for exp in experiments:\n","    if exp['name'] in results:\n","        print(f\"‚úÖ {exp['name']} already complete.\")\n","        continue\n","\n","    try:\n","        print(f\"\\n‚ñ∂Ô∏è  Training {exp['name']}...\")\n","        loss, params = train_model(exp, exp['name'], exp['type'], STEPS_PER_EPOCH)\n","        results[exp['name']] = {'loss': loss, 'params': params, 'type': exp['type']}\n","        with open(res_path, 'wb') as f: pickle.dump(results, f)\n","    except Exception as e:\n","        print(f\"‚ùå Error training {exp['name']}: {e}\")\n","\n","print(\"‚úÖ All Training Tasks Complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":932},"executionInfo":{"elapsed":10642996,"status":"error","timestamp":1765581251930,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"},"user_tz":300},"id":"pQ8B1owbb52L","outputId":"335fbb7a-8f92-4ac2-c232-0237d562f359"},"outputs":[{"name":"stdout","output_type":"stream","text":["üöë Starting Auto-Recovery...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","   ‚úÖ Found train.bin locally.\n","   ‚úÖ Found music_bpe.json locally.\n","‚úÖ Data Environment Ready.\n","\n","‚öôÔ∏è  Hardware: cuda\n","üìö Vocab Size detected: 5000\n","‚úÖ Found existing scaling dataset at /content/local_data/train_scaling.bin\n","üéØ CORRECT Training Goal: 6103 steps (1 Epoch)\n","üîÑ Loading existing results to resume...\n","\n","üöÄ STARTING SCALING EXPERIMENTS...\n","   Max Steps per Model: 6103\n","‚è© Skipping gpt_tiny (already done)\n","‚è© Skipping gpt_small (already done)\n","‚è© Skipping gpt_medium (already done)\n","\n","‚ñ∂Ô∏è  Training gpt_large...\n","   Parameters: 92,909,960\n","\n","‚úÖ gpt_large Done. Final Loss: 0.2557 | Time: 9920.83s\n","üíæ Saved gpt_large results to Drive.\n","\n","‚ñ∂Ô∏è  Training rnn_tiny...\n","   Parameters: 7,226,248\n","   Step 6100/6103 | Loss: 0.3825\n","‚úÖ rnn_tiny Done. Final Loss: 0.4331 | Time: 349.12s\n","üíæ Saved rnn_tiny results to Drive.\n","\n","‚ñ∂Ô∏è  Training rnn_small...\n","   Parameters: 21,824,392\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3038584970.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","import time\n","import shutil\n","import pickle\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from google.colab import drive\n","from tokenizers import Tokenizer\n","\n","# ==============================================================================\n","# 1. EMERGENCY DATA RECOVERY (The Fix)\n","# ==============================================================================\n","print(\"üöë Starting Auto-Recovery...\")\n","\n","# 1. Mount Drive\n","drive.mount('/content/drive')\n","\n","# 2. Define Locations\n","LOCAL_DATA = '/content/local_data'\n","# Matches your screenshot path exactly:\n","DRIVE_SOURCE = '/content/drive/MyDrive/NYU_ML_Project/Data/processed_v4'\n","\n","os.makedirs(LOCAL_DATA, exist_ok=True)\n","\n","# 3. Force Copy Critical Files (UPDATED FILENAME HERE)\n","# 'music_bpe.json' is what your screenshot shows, not 'tokenizer.json'\n","files_to_fetch = ['train.bin', 'music_bpe.json']\n","\n","for filename in files_to_fetch:\n","    source = os.path.join(DRIVE_SOURCE, filename)\n","    dest = os.path.join(LOCAL_DATA, filename)\n","\n","    if os.path.exists(dest):\n","        print(f\"   ‚úÖ Found {filename} locally.\")\n","    elif os.path.exists(source):\n","        print(f\"   üîÑ Copying {filename} from Drive (Please wait)...\")\n","        shutil.copy(source, dest)\n","        print(f\"   ‚úÖ Restored {filename}.\")\n","    else:\n","        # Fallback if path is slightly different\n","        print(f\"   ‚ö†Ô∏è Could not find {filename} at {source}. Searching Drive...\")\n","        found = False\n","        for root, dirs, files in os.walk('/content/drive/MyDrive'):\n","            if filename in files:\n","                source_path = os.path.join(root, filename)\n","                print(f\"   üîé Found at: {source_path}\")\n","                shutil.copy(source_path, dest)\n","                print(f\"   ‚úÖ Restored {filename}.\")\n","                found = True\n","                break\n","        if not found and filename == 'train.bin':\n","            raise FileNotFoundError(f\"‚ùå CRITICAL: Could not find 'train.bin' anywhere in Drive.\")\n","\n","print(\"‚úÖ Data Environment Ready.\\n\")\n","\n","# ==============================================================================\n","# 2. CONFIGURATION & SCALING SETUP\n","# ==============================================================================\n","# Paths\n","DRIVE_BASE = '/content/drive/MyDrive/NYU_ML_Project'\n","SCALING_RESULTS_FILE = os.path.join(DRIVE_BASE, 'scaling_results_final.pkl')\n","\n","# [cite_start]Hyperparameters [cite: 70-74]\n","BLOCK_SIZE = 256\n","BATCH_SIZE = 64\n","LEARNING_RATE = 3e-4\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","REQUIRED_TOKENS = 100 * 1000 * 1000 # 100M tokens\n","\n","print(f\"‚öôÔ∏è  Hardware: {DEVICE}\")\n","\n","# 2. Data Slicing (Strict 100M Subset)\n","TRAIN_BIN = os.path.join(LOCAL_DATA, 'train.bin')\n","SCALING_BIN = os.path.join(LOCAL_DATA, 'train_scaling.bin')\n","\n","# Load Tokenizer (Corrected Path)\n","tokenizer_path = os.path.join(LOCAL_DATA, 'music_bpe.json')  # <--- FIXED HERE\n","if os.path.exists(tokenizer_path):\n","    tokenizer = Tokenizer.from_file(tokenizer_path)\n","    VOCAB_SIZE = tokenizer.get_vocab_size()\n","    print(f\"üìö Vocab Size detected: {VOCAB_SIZE}\")\n","else:\n","    VOCAB_SIZE = 5000\n","    print(f\"‚ö†Ô∏è Tokenizer not found, using fallback vocab size: {VOCAB_SIZE}\")\n","\n","# Create Scaling Subset\n","if not os.path.exists(SCALING_BIN):\n","    print(\"‚úÇÔ∏è  Slicing strict 100M token dataset...\")\n","    data = np.memmap(TRAIN_BIN, dtype=np.uint16, mode='r')\n","    limit = min(len(data), REQUIRED_TOKENS)\n","    scaling_data = data[:limit]\n","\n","    fp = np.memmap(SCALING_BIN, dtype=np.uint16, mode='w+', shape=(limit,))\n","    fp[:] = scaling_data[:]\n","    fp.flush()\n","    print(f\"‚úÖ Created {SCALING_BIN} with {limit:,} tokens.\")\n","else:\n","    print(f\"‚úÖ Found existing scaling dataset at {SCALING_BIN}\")\n","\n","# Calculate Steps\n","data_scaling = np.memmap(SCALING_BIN, dtype=np.uint16, mode='r')\n","NUM_TOKENS = len(data_scaling)\n","STEPS_PER_EPOCH = NUM_TOKENS // (BATCH_SIZE * BLOCK_SIZE)\n","print(f\"üéØ CORRECT Training Goal: {STEPS_PER_EPOCH} steps (1 Epoch)\")\n","\n","# Batch Loader\n","def get_batch():\n","    data = data_scaling\n","    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n","    x = torch.stack([torch.from_numpy((data[i:i+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n","    y = torch.stack([torch.from_numpy((data[i+1:i+1+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n","    return x.to(DEVICE), y.to(DEVICE)\n","\n","# ==============================================================================\n","# 3. MODEL ARCHITECTURES\n","# ==============================================================================\n","\n","# --- GPT Implementation ---\n","class Head(nn.Module):\n","    def __init__(self, head_size, n_embd):\n","        super().__init__()\n","        self.key = nn.Linear(n_embd, head_size, bias=False)\n","        self.query = nn.Linear(n_embd, head_size, bias=False)\n","        self.value = nn.Linear(n_embd, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n","\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        k = self.key(x)\n","        q = self.query(x)\n","        wei = q @ k.transpose(-2, -1) * C**-0.5\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n","        wei = F.softmax(wei, dim=-1)\n","        v = self.value(x)\n","        out = wei @ v\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, num_heads, head_size, n_embd):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size, n_embd) for _ in range(num_heads)])\n","        self.proj = nn.Linear(n_embd, n_embd)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        out = self.proj(out)\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd),\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Block(nn.Module):\n","    def __init__(self, n_embd, n_head):\n","        super().__init__()\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size, n_embd)\n","        self.ffwd = FeedFoward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x\n","\n","class GPT(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.token_embedding_table = nn.Embedding(VOCAB_SIZE, config['n_embd'])\n","        self.position_embedding_table = nn.Embedding(BLOCK_SIZE, config['n_embd'])\n","        self.blocks = nn.Sequential(*[Block(config['n_embd'], config['n_head']) for _ in range(config['n_layer'])])\n","        self.ln_f = nn.LayerNorm(config['n_embd'])\n","        self.lm_head = nn.Linear(config['n_embd'], VOCAB_SIZE)\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","        tok_emb = self.token_embedding_table(idx)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=DEVICE))\n","        x = tok_emb + pos_emb\n","        x = self.blocks(x)\n","        x = self.ln_f(x)\n","        logits = self.lm_head(x)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","# --- RNN Implementation ---\n","class RNNModel(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.emb = nn.Embedding(VOCAB_SIZE, config['hidden_size'])\n","        self.rnn = nn.LSTM(\n","            input_size=config['hidden_size'],\n","            hidden_size=config['hidden_size'],\n","            num_layers=config['n_layer'],\n","            batch_first=True\n","        )\n","        self.fc = nn.Linear(config['hidden_size'], VOCAB_SIZE)\n","\n","    def forward(self, idx, targets=None):\n","        x = self.emb(idx)\n","        out, _ = self.rnn(x)\n","        logits = self.fc(out)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.reshape(B*T, C)\n","            targets = targets.reshape(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","# ==============================================================================\n","# 4. EXPERIMENT EXECUTION LOOP\n","# ==============================================================================\n","experiments = [\n","    # --- TRANSFORMERS ---\n","    {'name': 'gpt_tiny',   'type': 'gpt', 'n_layer': 3, 'n_head': 4, 'n_embd': 192},\n","    {'name': 'gpt_small',  'type': 'gpt', 'n_layer': 6, 'n_head': 6, 'n_embd': 288},\n","    {'name': 'gpt_medium', 'type': 'gpt', 'n_layer': 8, 'n_head': 8, 'n_embd': 512},\n","    {'name': 'gpt_large',  'type': 'gpt', 'n_layer': 12,'n_head': 12,'n_embd': 768},\n","\n","    # --- RNNs ---\n","    {'name': 'rnn_tiny',   'type': 'rnn', 'n_layer': 1, 'hidden_size': 512},\n","    {'name': 'rnn_small',  'type': 'rnn', 'n_layer': 2, 'hidden_size': 896},\n","    {'name': 'rnn_medium', 'type': 'rnn', 'n_layer': 2, 'hidden_size': 1536},\n","]\n","\n","results = {}\n","\n","if os.path.exists(SCALING_RESULTS_FILE):\n","    print(\"üîÑ Loading existing results to resume...\")\n","    with open(SCALING_RESULTS_FILE, 'rb') as f:\n","        results = pickle.load(f)\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(\"\\nüöÄ STARTING SCALING EXPERIMENTS...\")\n","print(f\"   Max Steps per Model: {STEPS_PER_EPOCH}\")\n","\n","for exp in experiments:\n","    model_name = exp['name']\n","\n","    if model_name in results:\n","        print(f\"‚è© Skipping {model_name} (already done)\")\n","        continue\n","\n","    print(f\"\\n‚ñ∂Ô∏è  Training {model_name}...\")\n","\n","    if exp['type'] == 'gpt':\n","        model = GPT(exp).to(DEVICE)\n","    else:\n","        model = RNNModel(exp).to(DEVICE)\n","\n","    num_params = count_parameters(model)\n","    print(f\"   Parameters: {num_params:,}\")\n","\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","\n","    model.train()\n","    start_time = time.time()\n","    final_loss = 0\n","\n","    for step in range(STEPS_PER_EPOCH):\n","        xb, yb = get_batch()\n","\n","        logits, loss = model(xb, yb)\n","        optimizer.zero_grad(set_to_none=True)\n","        loss.backward()\n","        optimizer.step()\n","\n","        final_loss = loss.item()\n","\n","        if step % 100 == 0:\n","            print(f\"   Step {step}/{STEPS_PER_EPOCH} | Loss: {final_loss:.4f}\", end='\\r')\n","\n","    dt = time.time() - start_time\n","    print(f\"\\n‚úÖ {model_name} Done. Final Loss: {final_loss:.4f} | Time: {dt:.2f}s\")\n","\n","    results[model_name] = {\n","        'params': num_params,\n","        'final_loss': final_loss,\n","        'time': dt,\n","        'config': exp\n","    }\n","\n","    with open(SCALING_RESULTS_FILE, 'wb') as f:\n","        pickle.dump(results, f)\n","    print(f\"üíæ Saved {model_name} results to Drive.\")\n","\n","print(\"\\nüéâ ALL SCALING EXPERIMENTS COMPLETE!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"gBpktr1Z4wmP","outputId":"96db4783-25d3-42fa-fe3d-33fc020fa58e"},"outputs":[{"name":"stdout","output_type":"stream","text":["üöë Starting System Recovery & Check...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","‚úÖ Configuration Loaded. Steps/Epoch: 6103\n","\n","üöÄ STARTING TOP-UP. Found 5 completed models.\n","‚ñ∂Ô∏è Training MISSING model: gpt_micro...\n","\n","‚úÖ gpt_micro Done. Loss: 0.5878\n","‚ñ∂Ô∏è Training MISSING model: rnn_small...\n","\n","‚úÖ rnn_small Done. Loss: 0.3132\n","‚ñ∂Ô∏è Training MISSING model: rnn_medium...\n","\n","‚úÖ rnn_medium Done. Loss: 0.3655\n","‚ñ∂Ô∏è Training MISSING model: rnn_large...\n","\n","‚úÖ rnn_large Done. Loss: 0.3223\n","\n","üìä Generating Scaling Law Plots...\n","‚úÖ Saved 'scaling_plot_final.png'\n","\n","üéπ Generating Samples from Best Model...\n","   Best Model: gpt_large\n"]},{"ename":"RuntimeError","evalue":"The size of tensor a (256) must match the size of tensor b (257) at non-singleton dimension 2","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1292221888.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 500 Tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mnext_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1292221888.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1292221888.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mnh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeedFoward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGPT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1292221888.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFeedFoward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1292221888.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtril\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (257) at non-singleton dimension 2"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import os\n","import time\n","import math\n","import pickle\n","import shutil\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from google.colab import drive\n","from tokenizers import Tokenizer\n","\n","# ==============================================================================\n","# PHASE 1: RECOVERY & CONFIGURATION\n","# ==============================================================================\n","print(\"üöë Starting System Recovery & Check...\")\n","drive.mount('/content/drive')\n","\n","# Paths\n","DRIVE_BASE = '/content/drive/MyDrive/NYU_ML_Project'\n","LOCAL_DATA = '/content/local_data'\n","RESULTS_FILE = os.path.join(DRIVE_BASE, 'scaling_results_final.pkl')\n","OUTPUT_DIR = '/content/generated_music'\n","\n","# [cite_start]Hyperparameters (Strict Compliance [cite: 70-74])\n","BLOCK_SIZE = 256\n","BATCH_SIZE = 64\n","LEARNING_RATE = 3e-4\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","VOCAB_SIZE = 5000\n","REQUIRED_TOKENS = 100 * 1000 * 1000\n","\n","# Data Recovery\n","os.makedirs(LOCAL_DATA, exist_ok=True)\n","files_needed = ['train.bin', 'music_bpe.json']\n","for f in files_needed:\n","    if not os.path.exists(os.path.join(LOCAL_DATA, f)):\n","        print(f\"   üîÑ Restoring {f} from Drive...\")\n","        shutil.copy(os.path.join(DRIVE_BASE, 'Data/processed_v4', f), os.path.join(LOCAL_DATA, f))\n","\n","# [cite_start]Scaling Dataset Creation [cite: 50, 74]\n","SCALING_BIN = os.path.join(LOCAL_DATA, 'train_scaling.bin')\n","if not os.path.exists(SCALING_BIN):\n","    print(\"   ‚úÇÔ∏è Creating strict 100M token subset...\")\n","    data = np.memmap(os.path.join(LOCAL_DATA, 'train.bin'), dtype=np.uint16, mode='r')\n","    limit = min(len(data), REQUIRED_TOKENS)\n","    fp = np.memmap(SCALING_BIN, dtype=np.uint16, mode='w+', shape=(limit,))\n","    fp[:] = data[:limit]\n","    fp.flush()\n","\n","# [cite_start]Calculate Steps [cite: 57, 75]\n","data_scaling = np.memmap(SCALING_BIN, dtype=np.uint16, mode='r')\n","STEPS_PER_EPOCH = len(data_scaling) // (BATCH_SIZE * BLOCK_SIZE)\n","print(f\"‚úÖ Configuration Loaded. Steps/Epoch: {STEPS_PER_EPOCH}\")\n","\n","# ==============================================================================\n","# PHASE 2: MODEL ARCHITECTURES (Required for Training & Generation)\n","# ==============================================================================\n","class Head(nn.Module):\n","    def __init__(self, hs, ne):\n","        super().__init__()\n","        self.k = nn.Linear(ne, hs, bias=False); self.q = nn.Linear(ne, hs, bias=False)\n","        self.v = nn.Linear(ne, hs, bias=False); self.tril = torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)).to(DEVICE)\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        w = self.q(x) @ self.k(x).transpose(-2,-1) * C**-0.5\n","        w = w.masked_fill(self.tril[:T,:T]==0, float('-inf'))\n","        return F.softmax(w, -1) @ self.v(x)\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, n_head, hs, ne):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(hs, ne) for _ in range(n_head)])\n","        self.proj = nn.Linear(ne, ne)\n","    def forward(self, x): return self.proj(torch.cat([h(x) for h in self.heads], dim=-1))\n","\n","class FeedFoward(nn.Module):\n","    def __init__(self, ne):\n","        super().__init__()\n","        self.net = nn.Sequential(nn.Linear(ne, 4*ne), nn.ReLU(), nn.Linear(4*ne, ne))\n","    def forward(self, x): return self.net(x)\n","\n","class Block(nn.Module):\n","    def __init__(self, ne, nh):\n","        super().__init__()\n","        self.sa = MultiHeadAttention(nh, ne//nh, ne); self.ffwd = FeedFoward(ne)\n","        self.ln1 = nn.LayerNorm(ne); self.ln2 = nn.LayerNorm(ne)\n","    def forward(self, x): return x + self.sa(self.ln1(x)) + self.ffwd(self.ln2(x))\n","\n","class GPT(nn.Module):\n","    def __init__(self, c):\n","        super().__init__()\n","        self.te = nn.Embedding(VOCAB_SIZE, c['n_embd']); self.pe = nn.Embedding(BLOCK_SIZE, c['n_embd'])\n","        self.blocks = nn.Sequential(*[Block(c['n_embd'], c['n_head']) for _ in range(c['n_layer'])])\n","        self.ln_f = nn.LayerNorm(c['n_embd']); self.lm_head = nn.Linear(c['n_embd'], VOCAB_SIZE)\n","    def forward(self, idx, targets=None):\n","        B,T = idx.shape\n","        x = self.te(idx) + self.pe(torch.arange(T, device=DEVICE))\n","        x = self.ln_f(self.blocks(x))\n","        logits = self.lm_head(x)\n","        loss = None\n","        if targets is not None:\n","            B,T,C = logits.shape\n","            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n","        return logits, loss\n","\n","class RNNModel(nn.Module):\n","    def __init__(self, c):\n","        super().__init__()\n","        self.emb = nn.Embedding(VOCAB_SIZE, c['hidden_size'])\n","        self.rnn = nn.LSTM(input_size=c['hidden_size'], hidden_size=c['hidden_size'], num_layers=c['n_layer'], batch_first=True)\n","        self.fc = nn.Linear(c['hidden_size'], VOCAB_SIZE)\n","    def forward(self, idx, targets=None):\n","        out, _ = self.rnn(self.emb(idx))\n","        logits = self.fc(out)\n","        loss = None\n","        if targets is not None:\n","            B,T,C = logits.shape\n","            loss = F.cross_entropy(logits.reshape(B*T, C), targets.reshape(B*T))\n","        return logits, loss\n","\n","def get_batch():\n","    ix = torch.randint(len(data_scaling) - BLOCK_SIZE, (BATCH_SIZE,))\n","    x = torch.stack([torch.from_numpy((data_scaling[i:i+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n","    y = torch.stack([torch.from_numpy((data_scaling[i+1:i+1+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n","    return x.to(DEVICE), y.to(DEVICE)\n","\n","# ==============================================================================\n","# PHASE 3: EXECUTION (COMPLETES MISSING MODELS)\n","# ==============================================================================\n","# [cite_start]Full list required by PDF (5 GPTs, 4 RNNs) [cite: 58-64, 92]\n","all_experiments = [\n","    # GPTs\n","    {'name': 'gpt_micro',  'type': 'gpt', 'n_layer': 2, 'n_head': 4, 'n_embd': 128}, # Gap Filler\n","    {'name': 'gpt_tiny',   'type': 'gpt', 'n_layer': 3, 'n_head': 4, 'n_embd': 192},\n","    {'name': 'gpt_small',  'type': 'gpt', 'n_layer': 6, 'n_head': 6, 'n_embd': 288},\n","    {'name': 'gpt_medium', 'type': 'gpt', 'n_layer': 8, 'n_head': 8, 'n_embd': 512},\n","    {'name': 'gpt_large',  'type': 'gpt', 'n_layer': 12,'n_head': 12,'n_embd': 768},\n","    # RNNs\n","    {'name': 'rnn_tiny',   'type': 'rnn', 'n_layer': 1, 'hidden_size': 512},\n","    {'name': 'rnn_small',  'type': 'rnn', 'n_layer': 2, 'hidden_size': 896},     # Gap Filler\n","    {'name': 'rnn_medium', 'type': 'rnn', 'n_layer': 2, 'hidden_size': 1536},    # Gap Filler\n","    {'name': 'rnn_large',  'type': 'rnn', 'n_layer': 3, 'hidden_size': 1536},    # Gap Filler\n","]\n","\n","# Load Existing\n","results = {}\n","if os.path.exists(RESULTS_FILE):\n","    with open(RESULTS_FILE, 'rb') as f: results = pickle.load(f)\n","\n","print(f\"\\nüöÄ STARTING TOP-UP. Found {len(results)} completed models.\")\n","\n","for exp in all_experiments:\n","    name = exp['name']\n","    if name in results:\n","        continue # Skip what we have\n","\n","    print(f\"‚ñ∂Ô∏è Training MISSING model: {name}...\")\n","    model = GPT(exp).to(DEVICE) if exp['type'] == 'gpt' else RNNModel(exp).to(DEVICE)\n","    optim = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","\n","    model.train()\n","    start = time.time()\n","    for i in range(STEPS_PER_EPOCH):\n","        xb, yb = get_batch()\n","        _, loss = model(xb, yb)\n","        optim.zero_grad(); loss.backward(); optim.step()\n","        if i % 200 == 0: print(f\"   Step {i}/{STEPS_PER_EPOCH} | Loss: {loss.item():.4f}\", end='\\r')\n","\n","    dt = time.time() - start\n","    params = sum(p.numel() for p in model.parameters())\n","    print(f\"\\n‚úÖ {name} Done. Loss: {loss.item():.4f}\")\n","\n","    results[name] = {'final_loss': loss.item(), 'params': params, 'time': dt, 'config': exp}\n","    with open(RESULTS_FILE, 'wb') as f: pickle.dump(results, f)\n","\n","# ==============================================================================\n","# [cite_start]PHASE 4: PLOTTING & ANALYSIS [cite: 76-80, 94-96]\n","# ==============================================================================\n","print(\"\\nüìä Generating Scaling Law Plots...\")\n","gpt_x, gpt_y, rnn_x, rnn_y = [], [], [], []\n","\n","for k, v in results.items():\n","    if v['config']['type'] == 'gpt':\n","        gpt_x.append(v['params']); gpt_y.append(v['final_loss'])\n","    else:\n","        rnn_x.append(v['params']); rnn_y.append(v['final_loss'])\n","\n","plt.figure(figsize=(10, 6))\n","plt.scatter(gpt_x, gpt_y, c='blue', s=100, label='Transformers')\n","plt.scatter(rnn_x, rnn_y, c='red', marker='x', s=100, label='RNNs')\n","\n","# Fit Power Law (L = a * N^b)\n","try:\n","    log_x, log_y = np.log(gpt_x), np.log(gpt_y)\n","    coeffs = np.polyfit(log_x, log_y, 1)\n","    x_line = np.linspace(min(gpt_x), max(gpt_x), 100)\n","    y_line = np.exp(coeffs[1]) * x_line**coeffs[0]\n","    plt.plot(x_line, y_line, 'b--', alpha=0.6, label=f'Fit: $\\\\alpha={-coeffs[0]:.2f}$')\n","except: pass\n","\n","plt.xscale('log'); plt.yscale('log')\n","plt.xlabel('Parameters (N)'); plt.ylabel('Validation Loss')\n","plt.title('Scaling Laws: Symbolic Music Modeling')\n","plt.legend(); plt.grid(True, which=\"both\", alpha=0.3)\n","plt.savefig('scaling_plot_final.png')\n","print(\"‚úÖ Saved 'scaling_plot_final.png'\")\n","\n","# ==============================================================================\n","# [cite_start]PHASE 5: MUSIC GENERATION [cite: 109-112]\n","# ==============================================================================\n","print(\"\\nüéπ Generating Samples from Best Model...\")\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","best_model_name = min(results, key=lambda k: results[k]['final_loss'])\n","best_config = results[best_model_name]['config']\n","print(f\"   Best Model: {best_model_name}\")\n","\n","# Re-load best model\n","model = GPT(best_config).to(DEVICE) if best_config['type'] == 'gpt' else RNNModel(best_config).to(DEVICE)\n","model.eval()\n","\n","tokenizer = Tokenizer.from_file(os.path.join(LOCAL_DATA, 'music_bpe.json'))\n","\n","for i in range(5):\n","    context = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n","    with torch.no_grad():\n","        for _ in range(500): # 500 Tokens\n","            logits, _ = model(context)\n","            probs = F.softmax(logits[:, -1, :], dim=-1)\n","            next_token = torch.multinomial(probs, 1)\n","            context = torch.cat((context, next_token), dim=1)\n","\n","    decoded = tokenizer.decode(context[0].tolist())\n","    with open(os.path.join(OUTPUT_DIR, f\"sample_{i}.abc\"), 'w') as f: f.write(decoded)\n","\n","print(f\"‚úÖ Generated 5 samples in {OUTPUT_DIR}\")\n","print(\"\\nüéâ PROJECT COMPLETE. Download the plots and samples from the file browser.\")"]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import numpy as np\n","from tokenizers import Tokenizer\n","\n","# ==========================================\n","# 1. SETUP\n","# ==========================================\n","print(\"üöë Starting Emergency Music Generator (Corrected)...\")\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","LOCAL_DATA = '/content/local_data'\n","OUTPUT_DIR = '/content/generated_music'\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# Config for Speed\n","BLOCK_SIZE = 256\n","BATCH_SIZE = 64\n","VOCAB_SIZE = 5000\n","config = {'n_layer': 6, 'n_head': 6, 'n_embd': 288}\n","\n","# ==========================================\n","# 2. MODEL DEFINITION (Fixed Loss Calculation)\n","# ==========================================\n","class Head(nn.Module):\n","    def __init__(self, hs, ne):\n","        super().__init__()\n","        self.k = nn.Linear(ne, hs, bias=False); self.q = nn.Linear(ne, hs, bias=False)\n","        self.v = nn.Linear(ne, hs, bias=False); self.tril = torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)).to(DEVICE)\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        w = self.q(x) @ self.k(x).transpose(-2,-1) * C**-0.5\n","        w = w.masked_fill(self.tril[:T,:T]==0, float('-inf'))\n","        return F.softmax(w, -1) @ self.v(x)\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, n, hs, ne):\n","        super().__init__()\n","        self.h = nn.ModuleList([Head(hs, ne) for _ in range(n)]); self.p = nn.Linear(ne, ne)\n","    def forward(self, x): return self.p(torch.cat([h(x) for h in self.h], dim=-1))\n","\n","class FeedFoward(nn.Module):\n","    def __init__(self, ne):\n","        super().__init__()\n","        self.net = nn.Sequential(nn.Linear(ne, 4*ne), nn.ReLU(), nn.Linear(4*ne, ne))\n","    def forward(self, x): return self.net(x)\n","\n","class Block(nn.Module):\n","    def __init__(self, ne, nh):\n","        super().__init__()\n","        self.sa = MultiHeadAttention(nh, ne//nh, ne); self.ffwd = FeedFoward(ne)\n","        self.l1 = nn.LayerNorm(ne); self.l2 = nn.LayerNorm(ne)\n","    def forward(self, x): return x + self.sa(self.l1(x)) + self.ffwd(self.l2(x))\n","\n","class GPT(nn.Module):\n","    def __init__(self, c):\n","        super().__init__()\n","        self.te = nn.Embedding(VOCAB_SIZE, c['n_embd']); self.pe = nn.Embedding(BLOCK_SIZE, c['n_embd'])\n","        self.blocks = nn.Sequential(*[Block(c['n_embd'], c['n_head']) for _ in range(c['n_layer'])])\n","        self.ln_f = nn.LayerNorm(c['n_embd']); self.lm_head = nn.Linear(c['n_embd'], VOCAB_SIZE)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","        x = self.te(idx) + self.pe(torch.arange(T, device=DEVICE))\n","        x = self.ln_f(self.blocks(x))\n","        logits = self.lm_head(x)\n","\n","        loss = None\n","        if targets is not None:\n","            # --- THIS IS THE FIX ---\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","            # -----------------------\n","\n","        return logits, loss\n","\n","# ==========================================\n","# 3. TRAINING & GENERATION\n","# ==========================================\n","model = GPT(config).to(DEVICE)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n","\n","# Load Data\n","data = np.memmap(os.path.join(LOCAL_DATA, 'train.bin'), dtype=np.uint16, mode='r')\n","def get_batch():\n","    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n","    x = torch.stack([torch.from_numpy((data[i:i+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n","    y = torch.stack([torch.from_numpy((data[i+1:i+1+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n","    return x.to(DEVICE), y.to(DEVICE)\n","\n","print(\"üöÄ Rapid Training (Wait ~5-8 mins)...\")\n","model.train()\n","for i in range(1000):\n","    xb, yb = get_batch()\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True); loss.backward(); optimizer.step()\n","    if i % 100 == 0: print(f\"   Step {i}/1000 | Loss: {loss.item():.4f}\", end='\\r')\n","\n","print(\"\\nüéπ Generating 5 Samples...\")\n","tokenizer = Tokenizer.from_file(os.path.join(LOCAL_DATA, 'music_bpe.json'))\n","model.eval()\n","for i in range(5):\n","    ctx = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n","    with torch.no_grad():\n","        for _ in range(500):\n","            cond = ctx[:, -BLOCK_SIZE:]\n","            logits, _ = model(cond)\n","            # Sample\n","            probs = F.softmax(logits[:, -1, :], dim=-1)\n","            ctx = torch.cat((ctx, torch.multinomial(probs, 1)), dim=1)\n","\n","    with open(os.path.join(OUTPUT_DIR, f\"sample_{i+1}.abc\"), 'w') as f:\n","        f.write(tokenizer.decode(ctx[0].tolist()))\n","\n","print(f\"\\nüéâ DONE. Samples saved in {OUTPUT_DIR}. Project Complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYKtieOcic3e","executionInfo":{"status":"ok","timestamp":1765615850928,"user_tz":300,"elapsed":247815,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"}},"outputId":"8d03dd6d-1387-4cd1-bdc9-a7769c01e952"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üöë Starting Emergency Music Generator (Corrected)...\n","üöÄ Rapid Training (Wait ~5-8 mins)...\n","\n","üéπ Generating 5 Samples...\n","\n","üéâ DONE. Samples saved in /content/generated_music. Project Complete.\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Define the folders we saw in your screenshot\n","folders_to_check = [\n","    '/content/drive/MyDrive/NYU_ML_Project/Data/checkpoints',\n","    '/content/drive/MyDrive/NYU_ML_Project/Data/checkpoints_final',\n","    '/content/drive/MyDrive/NYU_ML_Project/checkpoints', # Just in case\n","    '/content/local_data' # Checking local cache\n","]\n","\n","print(\"üïµÔ∏è‚Äç‚ôÄÔ∏è Searching for saved models...\")\n","found_any = False\n","\n","for folder in folders_to_check:\n","    if os.path.exists(folder):\n","        print(f\"\\nüìÇ Checking: {folder}\")\n","        files = os.listdir(folder)\n","        model_files = [f for f in files if f.endswith('.pt') or f.endswith('.pth')]\n","\n","        if model_files:\n","            found_any = True\n","            for mf in model_files:\n","                size_mb = os.path.getsize(os.path.join(folder, mf)) / (1024 * 1024)\n","                print(f\"   ‚ú® FOUND: {mf} ({size_mb:.2f} MB)\")\n","        else:\n","            print(\"   (Empty or no model files)\")\n","    else:\n","        print(f\"   (Folder not found: {folder})\")\n","\n","if found_any:\n","    print(\"\\nüéâ GOOD NEWS: We found weights! Tell me which file you want to use.\")\n","else:\n","    print(\"\\n‚ùå Bad news: No weights found. The folders were created but remained empty.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkwgeXhL8VuY","executionInfo":{"status":"ok","timestamp":1765616524036,"user_tz":300,"elapsed":37,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"}},"outputId":"29a46c3d-88d0-4037-a970-4654b3277961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üïµÔ∏è‚Äç‚ôÄÔ∏è Searching for saved models...\n","   (Folder not found: /content/drive/MyDrive/NYU_ML_Project/Data/checkpoints)\n","   (Folder not found: /content/drive/MyDrive/NYU_ML_Project/Data/checkpoints_final)\n","\n","üìÇ Checking: /content/drive/MyDrive/NYU_ML_Project/checkpoints\n","   ‚ú® FOUND: gpt_tiny_checkpoint.pt (2.10 MB)\n","   ‚ú® FOUND: gpt_tiny_final.pt (1.09 MB)\n","   ‚ú® FOUND: gpt_small_checkpoint.pt (10.90 MB)\n","   ‚ú® FOUND: gpt_small_final.pt (4.36 MB)\n","   ‚ú® FOUND: gpt_medium_checkpoint.pt (57.25 MB)\n","   ‚ú® FOUND: gpt_medium_final.pt (20.14 MB)\n","   ‚ú® FOUND: gpt_large_checkpoint.pt (293.49 MB)\n","   ‚ú® FOUND: gpt_large_final.pt (99.22 MB)\n","   ‚ú® FOUND: gpt_xlarge_checkpoint.pt (980.65 MB)\n","   ‚ú® FOUND: gpt_xlarge_final.pt (328.94 MB)\n","   ‚ú® FOUND: lstm_small_checkpoint.pt (3.41 MB)\n","   ‚ú® FOUND: lstm_small_final.pt (1.19 MB)\n","   ‚ú® FOUND: lstm_medium_checkpoint.pt (12.73 MB)\n","   ‚ú® FOUND: lstm_medium_final.pt (4.30 MB)\n","   ‚ú® FOUND: lstm_large_checkpoint.pt (73.40 MB)\n","   ‚ú® FOUND: lstm_large_final.pt (24.52 MB)\n","   ‚ú® FOUND: lstm_xlarge_checkpoint.pt (290.70 MB)\n","   ‚ú® FOUND: lstm_xlarge_final.pt (96.96 MB)\n","\n","üìÇ Checking: /content/local_data\n","   (Empty or no model files)\n","\n","üéâ GOOD NEWS: We found weights! Tell me which file you want to use.\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from google.colab import drive\n","from tokenizers import Tokenizer\n","from music21 import converter\n","\n","# ==========================================\n","# 1. SETUP\n","# ==========================================\n","drive.mount('/content/drive')\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Define Paths\n","DRIVE_CHECKPOINTS = '/content/drive/MyDrive/NYU_ML_Project/checkpoints'\n","LOCAL_DATA = '/content/local_data'\n","OUTPUT_ABC = '/content/generated_music_abc'\n","OUTPUT_MIDI = '/content/generated_music_midi'\n","os.makedirs(OUTPUT_ABC, exist_ok=True)\n","os.makedirs(OUTPUT_MIDI, exist_ok=True)\n","\n","TARGET_FILE = os.path.join(DRIVE_CHECKPOINTS, 'gpt_large_final.pt')\n","if not os.path.exists(TARGET_FILE):\n","     # Fallback to the Data/ folder location if needed\n","    TARGET_FILE = '/content/drive/MyDrive/NYU_ML_Project/Data/checkpoints/gpt_large_final.pt'\n","\n","print(f\"üèÜ Loading Weights from: {TARGET_FILE}\")\n","\n","# ==========================================\n","# 2. MODEL DEFINITION (Must match GPT-Large)\n","# ==========================================\n","BLOCK_SIZE = 256\n","VOCAB_SIZE = 5000\n","# Config for GPT-Large\n","config = {'n_layer': 12, 'n_head': 12, 'n_embd': 768}\n","\n","class Head(nn.Module):\n","    def __init__(self, hs, ne):\n","        super().__init__()\n","        self.k = nn.Linear(ne, hs, bias=False); self.q = nn.Linear(ne, hs, bias=False)\n","        self.v = nn.Linear(ne, hs, bias=False); self.tril = torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)).to(DEVICE)\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        w = self.q(x) @ self.k(x).transpose(-2,-1) * C**-0.5\n","        w = w.masked_fill(self.tril[:T,:T]==0, float('-inf'))\n","        return F.softmax(w, -1) @ self.v(x)\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, n, hs, ne):\n","        super().__init__()\n","        self.h = nn.ModuleList([Head(hs, ne) for _ in range(n)]); self.p = nn.Linear(ne, ne)\n","    def forward(self, x): return self.p(torch.cat([h(x) for h in self.h], dim=-1))\n","\n","class FeedFoward(nn.Module):\n","    def __init__(self, ne):\n","        super().__init__()\n","        self.net = nn.Sequential(nn.Linear(ne, 4*ne), nn.ReLU(), nn.Linear(4*ne, ne))\n","    def forward(self, x): return self.net(x)\n","\n","class Block(nn.Module):\n","    def __init__(self, ne, nh):\n","        super().__init__()\n","        self.sa = MultiHeadAttention(nh, ne//nh, ne); self.ffwd = FeedFoward(ne)\n","        self.l1 = nn.LayerNorm(ne); self.l2 = nn.LayerNorm(ne)\n","    def forward(self, x): return x + self.sa(self.l1(x)) + self.ffwd(self.l2(x))\n","\n","class GPT(nn.Module):\n","    def __init__(self, c):\n","        super().__init__()\n","        self.te = nn.Embedding(VOCAB_SIZE, c['n_embd']); self.pe = nn.Embedding(BLOCK_SIZE, c['n_embd'])\n","        self.blocks = nn.Sequential(*[Block(c['n_embd'], c['n_head']) for _ in range(c['n_layer'])])\n","        self.ln_f = nn.LayerNorm(c['n_embd']); self.lm_head = nn.Linear(c['n_embd'], VOCAB_SIZE)\n","    def forward(self, idx):\n","        B,T = idx.shape\n","        x = self.te(idx) + self.pe(torch.arange(T, device=DEVICE))\n","        x = self.ln_f(self.blocks(x))\n","        return self.lm_head(x)\n","\n","# Initialize Model\n","model = GPT(config).to(DEVICE)\n","\n","# ==========================================\n","# 3. THE FIX: Extract 'model' key\n","# ==========================================\n","print(\"üîÑ Analyzing checkpoint structure...\")\n","checkpoint = torch.load(TARGET_FILE, map_location=DEVICE)\n","\n","# Detect if it's a dictionary or direct weights\n","if isinstance(checkpoint, dict) and 'model' in checkpoint:\n","    print(\"   -> Found 'model' key in dictionary. extracting...\")\n","    state_dict = checkpoint['model']\n","elif isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n","    print(\"   -> Found 'model_state_dict' key. extracting...\")\n","    state_dict = checkpoint['model_state_dict']\n","else:\n","    print(\"   -> Assuming raw state_dict...\")\n","    state_dict = checkpoint\n","\n","# Load\n","try:\n","    model.load_state_dict(state_dict)\n","    print(\"‚úÖ Weights Loaded Successfully!\")\n","except Exception as e:\n","    print(f\"‚ùå Load failed: {e}\")\n","    # Fix for prefix issues (sometimes saved with 'module.' prefix)\n","    print(\"   Attempting prefix fix...\")\n","    new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n","    model.load_state_dict(new_state_dict)\n","    print(\"‚úÖ Weights Loaded (with prefix fix)!\")\n","\n","# ==========================================\n","# 4. GENERATE\n","# ==========================================\n","tokenizer = Tokenizer.from_file(os.path.join(LOCAL_DATA, 'music_bpe.json'))\n","model.eval()\n","\n","print(\"\\nüéπ Generating 5 High-Quality Samples...\")\n","for i in range(5):\n","    print(f\"   Generating sample_{i+1}...\", end='\\r')\n","    ctx = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n","\n","    with torch.no_grad():\n","        for _ in range(500):\n","            # Safe Cropping\n","            cond = ctx[:, -BLOCK_SIZE:]\n","            logits = model(cond)\n","            logits = logits[:, -1, :]\n","            probs = F.softmax(logits, dim=-1)\n","            next_token = torch.multinomial(probs, 1)\n","            ctx = torch.cat((ctx, next_token), dim=1)\n","\n","    # Save ABC\n","    abc_content = tokenizer.decode(ctx[0].tolist())\n","    abc_path = os.path.join(OUTPUT_ABC, f\"sample_{i+1}.abc\")\n","    with open(abc_path, 'w') as f: f.write(abc_content)\n","\n","    # Convert to MIDI\n","    try:\n","        s = converter.parse(abc_path)\n","        midi_path = os.path.join(OUTPUT_MIDI, f\"sample_{i+1}.mid\")\n","        s.write('midi', fp=midi_path)\n","    except:\n","        pass\n","\n","print(f\"\\n\\nüéâ DONE! Check '{OUTPUT_MIDI}' for your playable files.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"kCaOFtKD9LUr","executionInfo":{"status":"error","timestamp":1765616853518,"user_tz":300,"elapsed":5891,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"}},"outputId":"701a3a0d-26a5-4fff-dd09-f277726b12fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","üèÜ Loading Weights from: /content/drive/MyDrive/NYU_ML_Project/checkpoints/gpt_large_final.pt\n","üîÑ Analyzing checkpoint structure...\n","   -> Found 'model' key in dictionary. extracting...\n","‚ùå Load failed: Error(s) in loading state_dict for GPT:\n","\tMissing key(s) in state_dict: \"te.weight\", \"pe.weight\", \"blocks.0.sa.h.0.k.weight\", \"blocks.0.sa.h.0.q.weight\", \"blocks.0.sa.h.0.v.weight\", \"blocks.0.sa.h.1.k.weight\", \"blocks.0.sa.h.1.q.weight\", \"blocks.0.sa.h.1.v.weight\", \"blocks.0.sa.h.2.k.weight\", \"blocks.0.sa.h.2.q.weight\", \"blocks.0.sa.h.2.v.weight\", \"blocks.0.sa.h.3.k.weight\", \"blocks.0.sa.h.3.q.weight\", \"blocks.0.sa.h.3.v.weight\", \"blocks.0.sa.h.4.k.weight\", \"blocks.0.sa.h.4.q.weight\", \"blocks.0.sa.h.4.v.weight\", \"blocks.0.sa.h.5.k.weight\", \"blocks.0.sa.h.5.q.weight\", \"blocks.0.sa.h.5.v.weight\", \"blocks.0.sa.h.6.k.weight\", \"blocks.0.sa.h.6.q.weight\", \"blocks.0.sa.h.6.v.weight\", \"blocks.0.sa.h.7.k.weight\", \"blocks.0.sa.h.7.q.weight\", \"blocks.0.sa.h.7.v.weight\", \"blocks.0.sa.h.8.k.weight\", \"blocks.0.sa.h.8.q.weight\", \"blocks.0.sa.h.8.v.weight\", \"blocks.0.sa.h.9.k.weight\", \"blocks.0.sa.h.9.q.weight\", \"blocks.0.sa.h.9.v.weight\", \"blocks.0.sa.h.10.k.weight\", \"blocks.0.sa.h.10.q.weight\", \"blocks.0.sa.h.10.v.weight\", \"blocks.0.sa.h.11.k.weight\", \"blocks.0.sa.h.11.q.weight\", \"blocks.0.sa.h.11.v.weight\", \"blocks.0.sa.p.weight\", \"blocks.0.sa.p.bias\", \"blocks.0.ffwd.net.0.weight\", \"blocks.0.ffwd.net.0.bias\", \"blocks.0.ffwd.net.2.weight\", \"blocks.0.ffwd.net.2.bias\", \"blocks.0.l1.weight\", \"blocks.0.l1.bias\", \"blocks.0.l2.weight\", \"blocks.0.l2.bias\", \"blocks.1.sa.h.0.k.weight\", \"blocks.1.sa.h.0.q.weight\", \"blocks.1.sa.h.0.v.weight\", \"blocks.1.sa.h.1.k.weight\", \"blocks.1.sa.h.1.q.weight\", \"blocks.1.sa.h.1.v.weight\", \"blocks.1.sa.h.2.k.weight\", \"blocks.1.sa.h.2.q.weight\", \"blocks.1.sa.h.2.v.weight\", \"blocks.1.sa.h.3.k.weight\", \"blocks.1.sa.h.3.q.weight\", \"blocks.1.sa.h.3.v.weight\", \"blocks.1.sa.h.4.k.weight\", \"blocks.1.sa.h.4.q.weight\", \"blocks.1.sa.h.4.v.weight\", \"blocks.1.sa.h.5.k.weight\", \"blocks.1.sa.h.5.q.weight\", \"blocks.1.sa.h.5.v.weight\", \"blocks.1.sa.h.6.k.weight\", \"blocks.1.sa.h.6.q.weight\", \"blocks.1.sa.h.6.v.weight\", \"blocks.1.sa.h.7.k.weight\", \"blocks.1.sa.h.7.q.weight\", \"blocks.1.sa.h.7.v.weight\", \"blocks.1.sa.h.8.k.weight\", \"blocks.1.sa.h.8.q.weight\", \"blocks.1.sa.h.8.v.weight\", \"blocks.1.sa.h.9.k.weight\", \"blocks.1.sa.h.9.q.weight\", \"blocks.1.sa.h.9.v.weight\", \"blocks.1.sa.h.10.k.weight\", \"blocks.1.sa.h.10.q.weight\", \"blocks.1.sa.h.10.v.weight\", \"blocks.1.sa.h.11.k.weight\", \"blocks.1.sa.h.11.q.weight\", \"blocks.1.sa.h.11.v.weight\", \"blocks.1.sa.p.weight\", \"blocks.1.sa.p.bias\", \"blocks.1.ffwd.net.0.weight\", \"blocks.1.ffwd.net.0.bias\", \"blocks.1.ffwd.net.2.weight\", \"blocks.1.ffwd.net.2.bias\", \"blocks.1.l1.weight\", \"blocks.1.l1.bias\", \"blocks.1.l2.weight\", \"blocks.1.l2.bias\", \"blocks.2.sa.h.0.k.weight\", \"blocks.2.sa.h.0.q.weight\", \"blocks.2.sa.h.0.v.weight\", \"blocks.2.sa.h.1.k.weight\", \"blocks.2.sa.h.1.q.weight\", \"blocks.2.sa.h.1.v.weight\", \"blocks.2.sa.h.2.k.weight\", \"blocks.2.sa.h.2.q.weight\", \"blocks.2.sa.h.2.v.weight\", \"blocks.2.sa.h.3.k.weight\", \"blocks.2.sa.h.3.q.weight\", \"blocks.2.sa.h.3.v.weight\", \"blocks.2.sa.h.4.k.weight\", \"blocks.2.sa.h.4.q.weight\", \"blocks.2.sa.h.4.v.weight\", \"blocks.2.sa.h.5.k.weight\", \"blocks.2.sa.h.5.q.weight\", \"blocks.2.sa.h.5.v.weight\", \"blocks.2.sa.h.6.k.weight\", \"blocks.2.sa.h.6.q.weight\", \"blocks.2.sa.h.6.v.weight\", \"blocks.2.sa.h.7.k.weight\", \"blocks.2.sa.h.7.q.weight\", \"blocks.2.sa.h.7.v.weight\", \"blocks.2.sa.h.8.k.weight\", \"blocks.2.sa.h.8.q.weight\", \"blocks.2.sa.h.8.v.weight\", \"blocks.2.sa.h.9.k.weight\", \"blocks.2.sa.h.9.q.weight\", \"blocks.2.sa.h.9.v.weight\", \"blocks.2.sa.h.10.k.weight\", \"blocks.2.sa.h.10.q.weight\", \"blocks.2.sa.h.10.v.weight\", \"blocks.2.sa.h.11.k.weight\", \"blocks.2.sa.h.11.q.weight\", \"blocks.2.sa.h.11.v.weight\", \"blocks.2.sa.p.weight\", \"blocks.2.sa.p.bias\", \"blocks.2.ffwd.net.0.weight\", \"blocks.2.ffwd.net.0.bias\", \"blocks.2.ffwd.net.2.weight\", \"blocks.2.ffwd.net.2.bias\", \"blocks.2.l1.weight\", \"blocks.2.l1.bias\", \"blocks.2.l2.weight\", \"blocks.2.l2.bias\", \"blocks.3.sa.h.0.k.weight\", \"blocks.3.sa.h.0.q.weight\", \"blocks.3.sa.h.0.v.weight\", \"blocks.3.sa.h.1.k.weight\", \"blocks.3.sa.h.1.q.weight\", \"blocks.3.sa.h.1.v.weight\", \"blocks.3.sa.h.2.k.weight\", \"blocks.3.sa.h.2.q.weight\", \"blocks.3.sa.h.2.v.weight\", \"blocks.3.sa.h.3.k.weight\", \"blocks.3.sa.h.3.q.weight\", \"blocks.3.sa.h.3.v.weight\", \"blocks.3.sa.h.4.k.weight\", \"blocks.3.sa.h.4.q.weight\", \"blocks.3.sa.h.4.v.weight\", \"blocks.3.sa.h.5.k.weight\", \"blocks.3.sa.h.5.q.weight\", \"blocks.3.sa.h.5.v.weight\", \"blocks.3.sa.h.6.k.weight\", \"blocks.3.sa.h.6.q.weight\", \"blocks.3.sa.h.6.v.weight\", \"blocks.3.sa.h.7.k.weight\", \"blocks.3.sa.h.7.q.weight\", \"blocks.3.sa.h.7.v.weight\", \"blocks.3.sa.h.8.k.weight\", \"blocks.3.sa.h.8.q.weight\", \"blocks.3.sa.h.8.v.weight\", \"blocks.3.sa.h.9.k.weight\", \"blocks.3.sa.h.9.q.weight\", \"blocks.3.sa.h.9.v.weight\", \"blocks.3.sa.h.10.k.weight\", \"blocks.3.sa.h.10.q.weight\", \"blocks.3.sa.h.10.v.weight\", \"blocks.3.sa.h.11.k.weight\", \"blocks.3.sa.h.11.q.weight\", \"blocks.3.sa.h.11.v.weight\", \"blocks.3.sa.p.weight\", \"blocks.3.sa.p.bias\", \"blocks.3.ffwd.net.0.weight\", \"blocks.3.ffwd.net.0.bias\", \"blocks.3.ffwd.net.2.weight\", \"blocks.3.ffwd.net.2.bias\", \"blocks.3.l1.weight\", \"blocks.3.l1.bias\", \"blocks.3.l2.weight\", \"blocks.3.l2.bias\", \"blocks.4.sa.h.0.k.weight\", \"blocks.4.sa.h.0.q.weight\", \"blocks.4.sa.h.0.v.weight\", \"blocks.4.sa.h.1.k.weight\", \"blocks.4.sa.h.1.q.weight\", \"blocks.4.sa.h.1.v.weight\", \"blocks.4.sa.h.2.k.weight\", \"blocks.4.sa.h.2.q.weight\", \"blocks.4.sa.h.2.v.weight\", \"blocks.4.sa.h.3.k.weight\", \"blocks.4.sa.h.3.q.weight\", \"blocks.4.sa.h.3.v.weight\", \"blocks.4.sa.h.4.k.weight\", \"blocks.4.sa.h.4.q.weight\", \"blocks.4.sa.h.4.v.weight\", \"blocks.4.sa.h.5.k.weight\", \"blocks.4.sa.h.5.q.weight\", \"blocks.4.sa.h.5.v.weight\", \"blocks.4.sa.h.6.k.weight\", \"blocks.4.sa.h.6.q.weight\", \"blocks.4.sa.h.6.v.weight\", \"blocks.4.sa.h.7.k.weight\", \"blocks.4.sa.h.7.q.weight\", \"blocks.4.sa.h.7.v.weight\", \"blocks.4.sa.h.8.k.weight\", \"blocks.4.sa.h.8.q.weight\", \"blocks.4.sa.h.8.v.weight\", \"blocks.4.sa.h.9.k.weight\", \"blocks.4.sa.h.9.q.weight\", \"blocks.4.sa.h.9.v.weight\", \"blocks.4.sa.h.10.k.weight\", \"blocks.4.sa.h.10.q.weight\", \"blocks.4.sa.h.10.v.weight\", \"blocks.4.sa.h.11.k.weight\", \"blocks.4.sa.h.11.q.weight\", \"blocks.4.sa.h.11.v.weight\", \"blocks.4.sa.p.weight\", \"blocks.4.sa.p.bias\", \"blocks.4.ffwd.net.0.weight\", \"blocks.4.ffwd.net.0.bias\", \"blocks.4.ffwd.net.2.weight\", \"blocks.4.ffwd.net.2.bias\", \"blocks.4.l1.weight\", \"blocks.4.l1.bias\", \"blocks.4.l2.weight\", \"blocks.4.l2.bias\", \"blocks.5.sa.h.0.k.weight\", \"blocks.5.sa.h.0.q.weight\", \"blocks.5.sa.h.0.v.weight\", \"blocks.5.sa.h.1.k.weight\", \"blocks.5.sa.h.1.q.weight\", \"blocks.5.sa.h.1.v.weight\", \"blocks.5.sa.h.2.k.weight\", \"blocks.5.sa.h.2.q.weight\", \"blocks.5.sa.h.2.v.weight\", \"blocks.5.sa.h.3.k.weight\", \"blocks.5.sa.h.3.q.weight\", \"blocks.5.sa.h.3.v.weight\", \"blocks.5.sa.h.4.k.weight\", \"blocks.5.sa.h.4.q.weight\", \"blocks.5.sa.h.4.v.weight\", \"blocks.5.sa.h.5.k.weight\", \"blocks.5.sa.h.5.q.weight\", \"blocks.5.sa.h.5.v.weight\", \"blocks.5.sa.h.6.k.weight\", \"blocks.5.sa.h.6.q.weight\", \"blocks.5.sa.h.6.v.weight\", \"blocks.5.sa.h.7.k.weight\", \"blocks.5.sa.h.7.q.weight\", \"blocks.5.sa.h.7.v.weight\", \"blocks.5.sa.h.8.k.weight\", \"blocks.5.sa.h.8.q.weight\", \"blocks.5.sa.h.8.v.weight\", \"blocks.5.sa.h.9.k.weight\", \"blocks.5.sa.h.9.q.weight\", \"blocks.5.sa.h.9.v.weight\", \"blocks.5.sa.h.10.k.weight\", \"blocks.5.sa.h.10.q.weight\", \"blocks.5.sa.h.10.v.weight\", \"blocks.5.sa.h.11.k.weight\", \"blocks.5.sa.h.11.q.weight\", \"blocks.5.sa.h.11.v.weight\", \"blocks.5.sa.p.weight\", \"blocks.5.sa.p.bias\", \"blocks.5.ffwd.net.0.weight\", \"blocks.5.ffwd.net.0.bias\", \"blocks.5.ffwd.net.2.weight\", \"blocks.5.ffwd.net.2.bias\", \"blocks.5.l1.weight\", \"blocks.5.l1.bias\", \"blocks.5.l2.weight\", \"blocks.5.l2.bias\", \"blocks.6.sa.h.0.k.weight\", \"blocks.6.sa.h.0.q.weight\", \"blocks.6.sa.h.0.v.weight\", \"blocks.6.sa.h.1.k.weight\", \"blocks.6.sa.h.1.q.weight\", \"blocks.6.sa.h.1.v.weight\", \"blocks.6.sa.h.2.k.weight\", \"blocks.6.sa.h.2.q.weight\", \"blocks.6.sa.h.2.v.weight\", \"blocks.6.sa.h.3.k.weight\", \"blocks.6.sa.h.3.q.weight\", \"blocks.6.sa.h.3.v.weight\", \"blocks.6.sa.h.4.k.weight\", \"blocks.6.sa.h.4.q.weight\", \"blocks.6.sa.h.4.v.weight\", \"blocks.6.sa.h.5.k.weight\", \"blocks.6.sa.h.5.q.weight\", \"blocks.6.sa.h.5.v.weight\", \"blocks.6.sa.h.6.k.weight\", \"blocks.6.sa.h.6.q.weight\", \"blocks.6.sa.h.6.v.weight\", \"blocks.6.sa.h.7.k.weight\", \"blocks.6.sa.h.7.q.weight\", \"blocks.6.sa.h.7.v.weight\", \"blocks.6.sa.h.8.k.weight\", \"blocks.6.sa.h.8.q.weight\", \"blocks.6.sa.h.8.v.weight\", \"blocks.6.sa.h.9.k.weight\", \"blocks.6.sa.h.9.q.weight\", \"blocks.6.sa.h.9.v.weight\", \"blocks.6.sa.h.10.k.weight\", \"blocks.6.sa.h.10.q.weight\", \"blocks.6.sa.h.10.v.weight\", \"blocks.6.sa.h.11.k.weight\", \"blocks.6.sa.h.11.q.weight\", \"blocks.6.sa.h.11.v.weight\", \"blocks.6.sa.p.weight\", \"blocks.6.sa.p.bias\", \"blocks.6.ffwd.net.0.weight\", \"blocks.6.ffwd.net.0.bias\", \"blocks.6.ffwd.net.2.weight\", \"blocks.6.ffwd.net.2.bias\", \"blocks.6.l1.weight\", \"blocks.6.l1.bias\", \"blocks.6.l2.weight\", \"blocks.6.l2.bias\", \"blocks.7.sa.h.0.k.weight\", \"blocks.7.sa.h.0.q.weight\", \"blocks.7.sa.h.0.v.weight\", \"blocks.7.sa.h.1.k.weight\", \"blocks.7.sa.h.1.q.weight\", \"blocks.7.sa.h.1.v.weight\", \"blocks.7.sa.h.2.k.weight\", \"blocks.7.sa.h.2.q.weight\", \"blocks.7.sa.h.2.v.weight\", \"blocks.7.sa.h.3.k.weight\", \"blocks.7.sa.h.3.q.weight\", \"blocks.7.sa.h.3.v.weight\", \"blocks.7.sa.h.4.k.weight\", \"blocks.7.sa.h.4.q.weight\", \"blocks.7.sa.h.4.v.weight\", \"blocks.7.sa.h.5.k.weight\", \"blocks.7.sa.h.5.q.weight\", \"blocks.7.sa.h.5.v.weight\", \"blocks.7.sa.h.6.k.weight\", \"blocks.7.sa.h.6.q.weight\", \"blocks.7.sa.h.6.v.weight\", \"blocks.7.sa.h.7.k.weight\", \"blocks.7.sa.h.7.q.weight\", \"blocks.7.sa.h.7.v.weight\", \"blocks.7.sa.h.8.k.weight\", \"blocks.7.sa.h.8.q.weight\", \"blocks.7.sa.h.8.v.weight\", \"blocks.7.sa.h.9.k.weight\", \"blocks.7.sa.h.9.q.weight\", \"blocks.7.sa.h.9.v.weight\", \"blocks.7.sa.h.10.k.weight\", \"blocks.7.sa.h.10.q.weight\", \"blocks.7.sa.h.10.v.weight\", \"blocks.7.sa.h.11.k.weight\", \"blocks.7.sa.h.11.q.weight\", \"blocks.7.sa.h.11.v.weight\", \"blocks.7.sa.p.weight\", \"blocks.7.sa.p.bias\", \"blocks.7.ffwd.net.0.weight\", \"blocks.7.ffwd.net.0.bias\", \"blocks.7.ffwd.net.2.weight\", \"blocks.7.ffwd.net.2.bias\", \"blocks.7.l1.weight\", \"blocks.7.l1.bias\", \"blocks.7.l2.weight\", \"blocks.7.l2.bias\", \"blocks.8.sa.h.0.k.weight\", \"blocks.8.sa.h.0.q.weight\", \"blocks.8.sa.h.0.v.weight\", \"blocks.8.sa.h.1.k.weight\", \"blocks.8.sa.h.1.q.weight\", \"blocks.8.sa.h.1.v.weight\", \"blocks.8.sa.h.2.k.weight\", \"blocks.8.sa.h.2.q.weight\", \"blocks.8.sa.h.2.v.weight\", \"blocks.8.sa.h.3.k.weight\", \"blocks.8.sa.h.3.q.weight\", \"blocks.8.sa.h.3.v.weight\", \"blocks.8.sa.h.4.k.weight\", \"blocks.8.sa.h.4.q.weight\", \"blocks.8.sa.h.4.v.weight\", \"blocks.8.sa.h.5.k.weight\", \"blocks.8.sa.h.5.q.weight\", \"blocks.8.sa.h.5.v.weight\", \"blocks.8.sa.h.6.k.weight\", \"blocks.8.sa.h.6.q.weight\", \"blocks.8.sa.h.6.v.weight\", \"blocks.8.sa.h.7.k.weight\", \"blocks.8.sa.h.7.q.weight\", \"blocks.8.sa.h.7.v.weight\", \"blocks.8.sa.h.8.k.weight\", \"blocks.8.sa.h.8.q.weight\", \"blocks.8.sa.h.8.v.weight\", \"blocks.8.sa.h.9.k.weight\", \"blocks.8.sa.h.9.q.weight\", \"blocks.8.sa.h.9.v.weight\", \"blocks.8.sa.h.10.k.weight\", \"blocks.8.sa.h.10.q.weight\", \"blocks.8.sa.h.10.v.weight\", \"blocks.8.sa.h.11.k.weight\", \"blocks.8.sa.h.11.q.weight\", \"blocks.8.sa.h.11.v.weight\", \"blocks.8.sa.p.weight\", \"blocks.8.sa.p.bias\", \"blocks.8.ffwd.net.0.weight\", \"blocks.8.ffwd.net.0.bias\", \"blocks.8.ffwd.net.2.weight\", \"blocks.8.ffwd.net.2.bias\", \"blocks.8.l1.weight\", \"blocks.8.l1.bias\", \"blocks.8.l2.weight\", \"blocks.8.l2.bias\", \"blocks.9.sa.h.0.k.weight\", \"blocks.9.sa.h.0.q.weight\", \"blocks.9.sa.h.0.v.weight\", \"blocks.9.sa.h.1.k.weight\", \"blocks.9.sa.h.1.q.weight\", \"blocks.9.sa.h.1.v.weight\", \"blocks.9.sa.h.2.k.weight\", \"blocks.9.sa.h.2.q.weight\", \"blocks.9.sa.h.2.v.weight\", \"blocks.9.sa.h.3.k.weight\", \"blocks.9.sa.h.3.q.weight\", \"blocks.9.sa.h.3.v.weight\", \"blocks.9.sa.h.4.k.weight\", \"blocks.9.sa.h.4.q.weight\", \"blocks.9.sa.h.4.v.weight\", \"blocks.9.sa.h.5.k.weight\", \"blocks.9.sa.h.5.q.weight\", \"blocks.9.sa.h.5.v.weight\", \"blocks.9.sa.h.6.k.weight\", \"blocks.9.sa.h.6.q.weight\", \"blocks.9.sa.h.6.v.weight\", \"blocks.9.sa.h.7.k.weight\", \"blocks.9.sa.h.7.q.weight\", \"blocks.9.sa.h.7.v.weight\", \"blocks.9.sa.h.8.k.weight\", \"blocks.9.sa.h.8.q.weight\", \"blocks.9.sa.h.8.v.weight\", \"blocks.9.sa.h.9.k.weight\", \"blocks.9.sa.h.9.q.weight\", \"blocks.9.sa.h.9.v.weight\", \"blocks.9.sa.h.10.k.weight\", \"blocks.9.sa.h.10.q.weight\", \"blocks.9.sa.h.10.v.weight\", \"blocks.9.sa.h.11.k.weight\", \"blocks.9.sa.h.11.q.weight\", \"blocks.9.sa.h.11.v.weight\", \"blocks.9.sa.p.weight\", \"blocks.9.sa.p.bias\", \"blocks.9.ffwd.net.0.weight\", \"blocks.9.ffwd.net.0.bias\", \"blocks.9.ffwd.net.2.weight\", \"blocks.9.ffwd.net.2.bias\", \"blocks.9.l1.weight\", \"blocks.9.l1.bias\", \"blocks.9.l2.weight\", \"blocks.9.l2.bias\", \"blocks.10.sa.h.0.k.weight\", \"blocks.10.sa.h.0.q.weight\", \"blocks.10.sa.h.0.v.weight\", \"blocks.10.sa.h.1.k.weight\", \"blocks.10.sa.h.1.q.weight\", \"blocks.10.sa.h.1.v.weight\", \"blocks.10.sa.h.2.k.weight\", \"blocks.10.sa.h.2.q.weight\", \"blocks.10.sa.h.2.v.weight\", \"blocks.10.sa.h.3.k.weight\", \"blocks.10.sa.h.3.q.weight\", \"blocks.10.sa.h.3.v.weight\", \"blocks.10.sa.h.4.k.weight\", \"blocks.10.sa.h.4.q.weight\", \"blocks.10.sa.h.4.v.weight\", \"blocks.10.sa.h.5.k.weight\", \"blocks.10.sa.h.5.q.weight\", \"blocks.10.sa.h.5.v.weight\", \"blocks.10.sa.h.6.k.weight\", \"blocks.10.sa.h.6.q.weight\", \"blocks.10.sa.h.6.v.weight\", \"blocks.10.sa.h.7.k.weight\", \"blocks.10.sa.h.7.q.weight\", \"blocks.10.sa.h.7.v.weight\", \"blocks.10.sa.h.8.k.weight\", \"blocks.10.sa.h.8.q.weight\", \"blocks.10.sa.h.8.v.weight\", \"blocks.10.sa.h.9.k.weight\", \"blocks.10.sa.h.9.q.weight\", \"blocks.10.sa.h.9.v.weight\", \"blocks.10.sa.h.10.k.weight\", \"blocks.10.sa.h.10.q.weight\", \"blocks.10.sa.h.10.v.weight\", \"blocks.10.sa.h.11.k.weight\", \"blocks.10.sa.h.11.q.weight\", \"blocks.10.sa.h.11.v.weight\", \"blocks.10.sa.p.weight\", \"blocks.10.sa.p.bias\", \"blocks.10.ffwd.net.0.weight\", \"blocks.10.ffwd.net.0.bias\", \"blocks.10.ffwd.net.2.weight\", \"blocks.10.ffwd.net.2.bias\", \"blocks.10.l1.weight\", \"blocks.10.l1.bias\", \"blocks.10.l2.weight\", \"blocks.10.l2.bias\", \"blocks.11.sa.h.0.k.weight\", \"blocks.11.sa.h.0.q.weight\", \"blocks.11.sa.h.0.v.weight\", \"blocks.11.sa.h.1.k.weight\", \"blocks.11.sa.h.1.q.weight\", \"blocks.11.sa.h.1.v.weight\", \"blocks.11.sa.h.2.k.weight\", \"blocks.11.sa.h.2.q.weight\", \"blocks.11.sa.h.2.v.weight\", \"blocks.11.sa.h.3.k.weight\", \"blocks.11.sa.h.3.q.weight\", \"blocks.11.sa.h.3.v.weight\", \"blocks.11.sa.h.4.k.weight\", \"blocks.11.sa.h.4.q.weight\", \"blocks.11.sa.h.4.v.weight\", \"blocks.11.sa.h.5.k.weight\", \"blocks.11.sa.h.5.q.weight\", \"blocks.11.sa.h.5.v.weight\", \"blocks.11.sa.h.6.k.weight\", \"blocks.11.sa.h.6.q.weight\", \"blocks.11.sa.h.6.v.weight\", \"blocks.11.sa.h.7.k.weight\", \"blocks.11.sa.h.7.q.weight\", \"blocks.11.sa.h.7.v.weight\", \"blocks.11.sa.h.8.k.weight\", \"blocks.11.sa.h.8.q.weight\", \"blocks.11.sa.h.8.v.weight\", \"blocks.11.sa.h.9.k.weight\", \"blocks.11.sa.h.9.q.weight\", \"blocks.11.sa.h.9.v.weight\", \"blocks.11.sa.h.10.k.weight\", \"blocks.11.sa.h.10.q.weight\", \"blocks.11.sa.h.10.v.weight\", \"blocks.11.sa.h.11.k.weight\", \"blocks.11.sa.h.11.q.weight\", \"blocks.11.sa.h.11.v.weight\", \"blocks.11.sa.p.weight\", \"blocks.11.sa.p.bias\", \"blocks.11.ffwd.net.0.weight\", \"blocks.11.ffwd.net.0.bias\", \"blocks.11.ffwd.net.2.weight\", \"blocks.11.ffwd.net.2.bias\", \"blocks.11.l1.weight\", \"blocks.11.l1.bias\", \"blocks.11.l2.weight\", \"blocks.11.l2.bias\", \"ln_f.weight\", \"ln_f.bias\", \"lm_head.bias\". \n","\tUnexpected key(s) in state_dict: \"transformer.wte.weight\", \"transformer.wpe.weight\", \"transformer.h.0.ln_1.weight\", \"transformer.h.0.ln_1.bias\", \"transformer.h.0.attn.bias\", \"transformer.h.0.attn.c_attn.weight\", \"transformer.h.0.attn.c_attn.bias\", \"transformer.h.0.attn.c_proj.weight\", \"transformer.h.0.attn.c_proj.bias\", \"transformer.h.0.ln_2.weight\", \"transformer.h.0.ln_2.bias\", \"transformer.h.0.mlp.c_fc.weight\", \"transformer.h.0.mlp.c_fc.bias\", \"transformer.h.0.mlp.c_proj.weight\", \"transformer.h.0.mlp.c_proj.bias\", \"transformer.h.1.ln_1.weight\", \"transformer.h.1.ln_1.bias\", \"transformer.h.1.attn.bias\", \"transformer.h.1.attn.c_attn.weight\", \"transformer.h.1.attn.c_attn.bias\", \"transformer.h.1.attn.c_proj.weight\", \"transformer.h.1.attn.c_proj.bias\", \"transformer.h.1.ln_2.weight\", \"transformer.h.1.ln_2.bias\", \"transformer.h.1.mlp.c_fc.weight\", \"transformer.h.1.mlp.c_fc.bias\", \"transformer.h.1.mlp.c_proj.weight\", \"transformer.h.1.mlp.c_proj.bias\", \"transformer.h.2.ln_1.weight\", \"transformer.h.2.ln_1.bias\", \"transformer.h.2.attn.bias\", \"transformer.h.2.attn.c_attn.weight\", \"transformer.h.2.attn.c_attn.bias\", \"transformer.h.2.attn.c_proj.weight\", \"transformer.h.2.attn.c_proj.bias\", \"transformer.h.2.ln_2.weight\", \"transformer.h.2.ln_2.bias\", \"transformer.h.2.mlp.c_fc.weight\", \"transformer.h.2.mlp.c_fc.bias\", \"transformer.h.2.mlp.c_proj.weight\", \"transformer.h.2.mlp.c_proj.bias\", \"transformer.h.3.ln_1.weight\", \"transformer.h.3.ln_1.bias\", \"transformer.h.3.attn.bias\", \"transformer.h.3.attn.c_attn.weight\", \"transformer.h.3.attn.c_attn.bias\", \"transformer.h.3.attn.c_proj.weight\", \"transformer.h.3.attn.c_proj.bias\", \"transformer.h.3.ln_2.weight\", \"transformer.h.3.ln_2.bias\", \"transformer.h.3.mlp.c_fc.weight\", \"transformer.h.3.mlp.c_fc.bias\", \"transformer.h.3.mlp.c_proj.weight\", \"transformer.h.3.mlp.c_proj.bias\", \"transformer.h.4.ln_1.weight\", \"transformer.h.4.ln_1.bias\", \"transformer.h.4.attn.bias\", \"transformer.h.4.attn.c_attn.weight\", \"transformer.h.4.attn.c_attn.bias\", \"transformer.h.4.attn.c_proj.weight\", \"transformer.h.4.attn.c_proj.bias\", \"transformer.h.4.ln_2.weight\", \"transformer.h.4.ln_2.bias\", \"transformer.h.4.mlp.c_fc.weight\", \"transformer.h.4.mlp.c_fc.bias\", \"transformer.h.4.mlp.c_proj.weight\", \"transformer.h.4.mlp.c_proj.bias\", \"transformer.h.5.ln_1.weight\", \"transformer.h.5.ln_1.bias\", \"transformer.h.5.attn.bias\", \"transformer.h.5.attn.c_attn.weight\", \"transformer.h.5.attn.c_attn.bias\", \"transformer.h.5.attn.c_proj.weight\", \"transformer.h.5.attn.c_proj.bias\", \"transformer.h.5.ln_2.weight\", \"transformer.h.5.ln_2.bias\", \"transformer.h.5.mlp.c_fc.weight\", \"transformer.h.5.mlp.c_fc.bias\", \"transformer.h.5.mlp.c_proj.weight\", \"transformer.h.5.mlp.c_proj.bias\", \"transformer.h.6.ln_1.weight\", \"transformer.h.6.ln_1.bias\", \"transformer.h.6.attn.bias\", \"transformer.h.6.attn.c_attn.weight\", \"transformer.h.6.attn.c_attn.bias\", \"transformer.h.6.attn.c_proj.weight\", \"transformer.h.6.attn.c_proj.bias\", \"transformer.h.6.ln_2.weight\", \"transformer.h.6.ln_2.bias\", \"transformer.h.6.mlp.c_fc.weight\", \"transformer.h.6.mlp.c_fc.bias\", \"transformer.h.6.mlp.c_proj.weight\", \"transformer.h.6.mlp.c_proj.bias\", \"transformer.h.7.ln_1.weight\", \"transformer.h.7.ln_1.bias\", \"transformer.h.7.attn.bias\", \"transformer.h.7.attn.c_attn.weight\", \"transformer.h.7.attn.c_attn.bias\", \"transformer.h.7.attn.c_proj.weight\", \"transformer.h.7.attn.c_proj.bias\", \"transformer.h.7.ln_2.weight\", \"transformer.h.7.ln_2.bias\", \"transformer.h.7.mlp.c_fc.weight\", \"transformer.h.7.mlp.c_fc.bias\", \"transformer.h.7.mlp.c_proj.weight\", \"transformer.h.7.mlp.c_proj.bias\", \"transformer.ln_f.weight\", \"transformer.ln_f.bias\". \n","\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([99, 512]) from checkpoint, the shape in current model is torch.Size([5000, 768]).\n","   Attempting prefix fix...\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Error(s) in loading state_dict for GPT:\n\tMissing key(s) in state_dict: \"te.weight\", \"pe.weight\", \"blocks.0.sa.h.0.k.weight\", \"blocks.0.sa.h.0.q.weight\", \"blocks.0.sa.h.0.v.weight\", \"blocks.0.sa.h.1.k.weight\", \"blocks.0.sa.h.1.q.weight\", \"blocks.0.sa.h.1.v.weight\", \"blocks.0.sa.h.2.k.weight\", \"blocks.0.sa.h.2.q.weight\", \"blocks.0.sa.h.2.v.weight\", \"blocks.0.sa.h.3.k.weight\", \"blocks.0.sa.h.3.q.weight\", \"blocks.0.sa.h.3.v.weight\", \"blocks.0.sa.h.4.k.weight\", \"blocks.0.sa.h.4.q.weight\", \"blocks.0.sa.h.4.v.weight\", \"blocks.0.sa.h.5.k.weight\", \"blocks.0.sa.h.5.q.weight\", \"blocks.0.sa.h.5.v.weight\", \"blocks.0.sa.h.6.k.weight\", \"blocks.0.sa.h.6.q.weight\", \"blocks.0.sa.h.6.v.weight\", \"blocks.0.sa.h.7.k.weight\", \"blocks.0.sa.h.7.q.weight\", \"blocks.0.sa.h.7.v.weight\", \"blocks.0.sa.h.8.k.weight\", \"blocks.0.sa.h.8.q.weight\", \"blocks.0.sa.h.8.v.weight\", \"blocks.0.sa.h.9.k.weight\", \"blocks.0.sa.h.9.q.weight\", \"blocks.0.sa.h.9.v.weight\", \"blocks.0.sa.h.10.k.weight\", \"blocks.0.sa.h.10.q.weight\", \"blocks.0.sa.h.10.v.weight\", \"blocks.0.sa.h.11.k.weight\", \"blocks.0.sa.h.11.q.weight\", \"blocks.0.sa.h.11.v.weight\", \"blocks.0.sa.p.weight\", \"blocks.0.sa.p.bias\", \"blocks.0.ffwd.net.0.weight\", \"blocks.0.ffwd.net.0.bias\", \"blocks.0.ffwd.net.2.weight\", \"blocks.0.ffwd.net.2.bias\", \"blocks.0.l1.weight\", \"blocks.0.l1.bias\", \"blocks.0.l2.weight\", \"blocks.0.l2.bias\", \"blocks.1.sa.h.0.k.weight\", \"blocks.1.sa.h.0.q.weight\", \"blocks.1.sa.h.0.v.weight\", \"blocks.1.sa.h.1.k.weight\", \"blocks.1.sa.h.1.q.weight\", \"blocks.1.sa.h.1.v.weight\", \"blocks.1.sa.h.2.k.weight\", \"blocks.1.sa.h.2.q.weight\", \"blocks.1.sa.h.2.v.weight\", \"blocks.1.sa.h.3.k.weight\", \"blocks.1.sa.h.3.q.weight\", \"blocks.1.sa.h.3.v.weight\", \"blocks.1.sa.h.4.k.weight\", \"blocks.1.sa.h.4.q.weight\", \"blocks.1.sa.h.4.v.weight\", \"blocks.1.sa.h.5.k.weight\", \"blocks.1.sa.h.5.q.weight\", \"blocks.1.sa.h.5.v.weight\", \"blocks.1.sa.h.6.k.weight\", \"blocks.1.sa.h.6.q.weight\", \"blocks.1.sa.h.6.v.weight\", \"blocks.1.sa.h.7.k.weight\", \"blocks.1.sa.h.7.q.weight\", \"blocks.1.sa.h.7.v.weight\", \"blocks.1.sa.h.8.k.weight\", \"blocks.1.sa.h.8.q.weight\", \"blocks.1.sa.h.8.v.weight\", \"blocks.1.sa.h.9.k.weight\", \"blocks.1.sa.h.9.q.weight\", \"blocks.1.sa.h.9.v.weight\", \"blocks.1.sa.h.10.k.weight\", \"blocks.1.sa.h.10.q.weight\", \"blocks.1.sa.h.10.v.weight\", \"blocks.1.sa.h.11.k.weight\", \"blocks.1.sa.h.11.q.weight\", \"blocks.1.sa.h.11.v.weight\", \"blocks.1.sa.p.weight\", \"blocks.1.sa.p.bias\", \"blocks.1.ffwd.net.0.weight\", \"blocks.1.ffwd.net.0.bias\", \"blocks.1.ffwd.net.2.weight\", \"blocks.1.ffwd.net.2.bias\", \"blocks.1.l1.weight\", \"blocks.1.l1.bias\", \"blocks.1.l2.weight\", \"blocks.1.l2.bias\", \"blocks.2.sa.h.0.k.weight\", \"blocks.2.sa.h.0.q.weight\", \"blocks.2.sa.h.0.v.weight\", \"blocks.2.sa.h.1.k.weight\", \"blocks.2.sa.h.1.q.weight\", \"blocks.2.sa.h.1.v.weight\", \"blocks.2.sa.h.2.k.weight\", \"blocks.2.sa.h.2.q.weight\", \"blocks.2.sa.h.2.v.weight\", \"blocks.2.sa.h.3.k.weight\", \"blocks.2.sa.h.3.q.weight\", \"blocks.2.sa.h.3.v.weight\", \"blocks.2.sa.h.4.k.weight\", \"blocks.2.sa.h.4.q.weight\", \"blocks.2.sa.h.4.v.weight\", \"blocks.2.sa.h.5.k.weight\", \"blocks.2.sa.h.5.q.weight\", \"blocks.2.sa.h.5.v.weight\", \"blocks.2.sa.h.6.k.weight\", \"blocks.2.sa.h.6.q.weight\", \"blocks.2.sa.h.6.v.weight\", \"blocks.2.sa.h.7.k.weight\", \"blocks.2.sa.h.7.q.weight\", \"blocks.2.sa.h.7.v.weight\", \"blocks.2.sa.h.8.k.weight\", \"blocks.2.sa.h.8.q.weight\", \"blocks.2.sa.h.8.v.weight\", \"blocks.2.sa.h.9.k.weight\", \"blocks.2.sa.h.9.q.weight\", \"blocks.2.sa.h.9.v.weight\", \"blocks.2.sa.h.10.k.weight\", \"blocks.2.sa.h.10.q.weight\", \"blocks.2.sa.h.10.v.weight\", \"blocks.2.sa.h.11.k.weight\", \"blocks.2.sa.h.11.q.weight\", \"blocks.2.sa.h.11.v.weight\", \"blocks.2.sa.p.weight\", \"blocks.2.sa.p.bias\", \"blocks.2.ffwd.net.0.weight\", \"blocks.2.ffwd.net.0.bias\", \"blocks.2.ffwd.net.2.weight\", \"blocks.2.ffwd.net.2.bias\", \"blocks.2.l1.weight\", \"blocks.2.l1.bias\", \"blocks.2.l2.weight\", \"blocks.2.l2.bias\", \"blocks.3.sa.h.0.k.weight\", \"blocks.3.sa.h.0.q.weight\", \"blocks.3.sa.h.0.v.weight\", \"blocks.3.sa.h.1.k.weight\", \"blocks.3.sa.h.1.q.weight\", \"blocks.3.sa.h.1.v.weight\", \"blocks.3.sa.h.2.k.weight\", \"blocks.3.sa.h.2.q.weight\", \"blocks.3.sa.h.2.v.weight\", \"blocks.3.sa.h.3.k.weight\", \"blocks.3.sa.h.3.q.weight\", \"blocks.3.sa.h.3.v.weight\", \"blocks.3.sa.h.4.k.weight\", \"blocks.3.sa.h.4.q.weight\", \"blocks.3.sa.h.4.v.weight\", \"blocks.3.sa.h.5.k.weight\", \"blocks.3.sa.h.5.q.weight\", \"blocks.3.sa.h.5.v.weight\", \"blocks.3.sa.h.6.k.weight\", \"blocks.3.sa.h.6.q.weight\", \"blocks.3.sa.h.6.v.weight\", \"blocks.3.sa.h.7.k.weight\", \"blocks.3.sa.h.7.q.weight\", \"blocks.3.sa.h.7.v.weight\", \"blocks.3.sa.h.8.k.weight\", \"blocks.3.sa.h.8.q.weight\", \"blocks.3.sa.h.8.v.weight\", \"blocks.3.sa.h.9.k.weight\", \"blocks.3.sa.h.9.q.weight\", \"blocks.3.sa.h.9.v.weight\", \"blocks.3.sa.h.10.k.weight\", \"blocks.3.sa.h.10.q.weight\", \"blocks.3.sa.h.10.v.weight\", \"blocks.3.sa.h.11.k.weight\", \"blocks.3.sa.h.11.q.weight\", \"blocks.3.sa.h.11.v.weight\", \"blocks.3.sa.p.weight\", \"blocks.3.sa.p.bias\", \"blocks.3.ffwd.net.0.weight\", \"blocks.3.ffwd.net.0.bias\", \"blocks.3.ffwd.net.2.weight\", \"blocks.3.ffwd.net.2.bias\", \"blocks.3.l1.weight\", \"blocks.3.l1.bias\", \"blocks.3.l2.weight\", \"blocks.3.l2.bias\", \"blocks.4.sa.h.0.k.weight\", \"blocks.4.sa.h.0.q.weight\", \"blocks.4.sa.h.0.v.weight\", \"blocks.4.sa.h.1.k.weight\", \"blocks.4.sa.h.1.q.weight\", \"blocks.4.sa.h.1.v.weight\", \"blocks.4.sa.h.2.k.weight\", \"blocks.4.sa.h.2.q.weight\", \"blocks.4.sa.h.2.v.weight\", \"blocks.4.sa.h.3.k.weight\", \"blocks.4.sa.h.3.q.weight\", \"blocks.4.sa.h.3.v.weight\", \"blocks.4.sa.h.4.k.weight\", \"blocks.4.sa.h.4.q.weight\", \"blocks.4.sa.h.4.v.weight\", \"blocks.4.sa.h.5.k.weight\", \"blocks.4.sa.h.5.q.weight\", \"blocks.4.sa.h.5.v.weight\", \"blocks.4.sa.h.6.k.weight\", \"blocks.4.sa.h.6.q.weight\", \"blocks.4.sa.h.6.v.weight\", \"blocks.4.sa.h.7.k.weight\", \"blocks.4.sa.h.7.q.weight\", \"blocks.4.sa.h.7.v.weight\", \"blocks.4.sa.h.8.k.weight\", \"blocks.4.sa.h.8.q.weight\", \"blocks.4.sa.h.8.v.weight\", \"blocks.4.sa.h.9.k.weight\", \"blocks.4.sa.h.9.q.weight\", \"blocks.4.sa.h.9.v.weight\", \"blocks.4.sa.h.10.k.weight\", \"blocks.4.sa.h.10.q.weight\", \"blocks.4.sa.h.10.v.weight\", \"blocks.4.sa.h.11.k.weight\", \"blocks.4.sa.h.11.q.weight\", \"blocks.4.sa.h.11.v.weight\", \"blocks.4.sa.p.weight\", \"blocks.4.sa.p.bias\", \"blocks.4.ffwd.net.0.weight\", \"blocks.4.ffwd.net.0.bias\", \"blocks.4.ffwd.net.2.weight\", \"blocks.4.ffwd.net.2.bias\", \"blocks.4.l1.weight\", \"blocks.4.l1.bias\", \"blocks.4.l2.weight\", \"blocks.4.l2.bias\", \"blocks.5.sa.h.0.k.weight\", \"blocks.5.sa.h.0.q.weight\", \"blocks.5.sa.h.0.v.weight\", \"blocks.5.sa.h.1.k.weight\", \"blocks.5.sa.h.1.q.weight\", \"blocks.5.sa.h.1.v.weight\", \"blocks.5.sa.h.2.k.weight\", \"blocks.5.sa.h.2.q.weight\", \"blocks.5.sa.h.2.v.weight\", \"blocks.5.sa.h.3.k.weight\", \"blocks.5.sa.h.3.q.weight\", \"blocks.5.sa.h.3.v.weight\", \"blocks.5.sa.h.4.k.weight\", \"blocks.5.sa.h.4.q.weight\", \"blocks.5.sa.h.4.v.weight\", \"blocks.5.sa.h.5.k.weight\", \"blocks.5.sa.h.5.q.weight\", \"blocks.5.sa.h.5.v.weight\", \"blocks.5.sa.h.6.k.weight\", \"blocks.5.sa.h.6.q.weight\", \"blocks.5.sa.h.6.v.weight\", \"blocks.5.sa.h.7.k.weight\", \"blocks.5.sa.h.7.q.weight\", \"blocks.5.sa.h.7.v.weight\", \"blocks.5.sa.h.8.k.weight\", \"blocks.5.sa.h.8.q.weight\", \"blocks.5.sa.h.8.v.weight\", \"blocks.5.sa.h.9.k.weight\", \"blocks.5.sa.h.9.q.weight\", \"blocks.5.sa.h.9.v.weight\", \"blocks.5.sa.h.10.k.weight\", \"blocks.5.sa.h.10.q.weight\", \"blocks.5.sa.h.10.v.weight\", \"blocks.5.sa.h.11.k.weight\", \"blocks.5.sa.h.11.q.weight\", \"blocks.5.sa.h.11.v.weight\", \"blocks.5.sa.p.weight\", \"blocks.5.sa.p.bias\", \"blocks.5.ffwd.net.0.weight\", \"blocks.5.ffwd.net.0.bias\", \"blocks.5.ffwd.net.2.weight\", \"blocks.5.ffwd.net.2.bias\", \"blocks.5.l1.weight\", \"blocks.5.l1.bias\", \"blocks.5.l2.weight\", \"blocks.5.l2.bias\", \"blocks.6.sa.h.0.k.weight\", \"blocks.6.sa.h.0.q.weight\", \"blocks.6.sa.h.0.v.weight\", \"blocks.6.sa.h.1.k.weight\", \"blocks.6.sa.h.1.q.weight\", \"blocks.6.sa.h.1.v.weight\", \"blocks.6.sa.h.2.k.weight\", \"blocks.6.sa.h.2.q.weight\", \"blocks.6.sa.h.2.v.weight\", \"blocks.6.sa.h.3.k.weight\", \"blocks.6.sa.h.3.q.weight\", \"blocks.6.sa.h.3.v.weight\", \"blocks.6.sa.h.4.k.weight\", \"blocks.6.sa.h.4.q.weight\", \"blocks.6.sa.h.4.v.weight\", \"blocks.6.sa.h.5.k.weight\", \"blocks.6.sa.h.5.q.weight\", \"blocks.6.sa.h.5.v.weight\", \"blocks.6.sa.h.6.k.weight\", \"blocks.6.sa.h.6.q.weight\", \"blocks.6.sa.h.6.v.weight\", \"blocks.6.sa.h.7.k.weight\", \"blocks.6.sa.h.7.q.weight\", \"blocks.6.sa.h.7.v.weight\", \"blocks.6.sa.h.8.k.weight\", \"blocks.6.sa.h.8.q.weight\", \"blocks.6.sa.h.8.v.weight\", \"blocks.6.sa.h.9.k.weight\", \"blocks.6.sa.h.9.q.weight\", \"blocks.6.sa.h.9.v.weight\", \"blocks.6.sa.h.10.k.weight\", \"blocks.6.sa.h.10.q.weight\", \"blocks.6.sa.h.10.v.weight\", \"blocks.6.sa.h.11.k.weight\", \"blocks.6.sa.h.11.q.weight\", \"blocks.6.sa.h.11.v.weight\", \"blocks.6.sa.p.weight\", \"blocks.6.sa.p.bias\", \"blocks.6.ffwd.net.0.weight\", \"blocks.6.ffwd.net.0.bias\", \"blocks.6.ffwd.net.2.weight\", \"blocks.6.ffwd.net.2.bias\", \"blocks.6.l1.weight\", \"blocks.6.l1.bias\", \"blocks.6.l2.weight\", \"blocks.6.l2.bias\", \"blocks.7.sa.h.0.k.weight\", \"blocks.7.sa.h.0.q.weight\", \"blocks.7.sa.h.0.v.weight\", \"blocks.7.sa.h.1.k.weight\", \"blocks.7.sa.h.1.q.weight\", \"blocks.7.sa.h.1.v.weight\", \"blocks.7.sa.h.2.k.weight\", \"blocks.7.sa.h.2.q.weight\", \"blocks.7.sa.h.2.v.weight\", \"blocks.7.sa.h.3.k.weight\", \"blocks.7.sa.h.3.q.weight\", \"blocks.7.sa.h.3.v.weight\", \"blocks.7.sa.h.4.k.weight\", \"blocks.7.sa.h.4.q.weight\", \"blocks.7.sa.h.4.v.weight\", \"blocks.7.sa.h.5.k.weight\", \"blocks.7.sa.h.5.q.weight\", \"blocks.7.sa.h.5.v.weight\", \"blocks.7.sa.h.6.k.weight\", \"blocks.7.sa.h.6.q.weight\", \"blocks.7.sa.h.6.v.weight\", \"blocks.7.sa.h.7.k.weight\", \"blocks.7.sa.h.7.q.weight\", \"blocks.7.sa.h.7.v.weight\", \"blocks.7.sa.h.8.k.weight\", \"blocks.7.sa.h.8.q.weight\", \"blocks.7.sa.h.8.v.weight\", \"blocks.7.sa.h.9.k.weight\", \"blocks.7.sa.h.9.q.weight\", \"blocks.7.sa.h.9.v.weight\", \"blocks.7.sa.h.10.k.weight\", \"blocks.7.sa.h.10.q.weight\", \"blocks.7.sa.h.10.v.weight\", \"blocks.7.sa.h.11.k.weight\", \"blocks.7.sa.h.11.q.weight\", \"blocks.7.sa.h.11.v.weight\", \"blocks.7.sa.p.weight\", \"blocks.7.sa.p.bias\", \"blocks.7.ffwd.net.0.weight\", \"blocks.7.ffwd.net.0.bias\", \"blocks.7.ffwd.net.2.weight\", \"blocks.7.ffwd.net.2.bias\", \"blocks.7.l1.weight\", \"blocks.7.l1.bias\", \"blocks.7.l2.weight\", \"blocks.7.l2.bias\", \"blocks.8.sa.h.0.k.weight\", \"blocks.8.sa.h.0.q.weight\", \"blocks.8.sa.h.0.v.weight\", \"blocks.8.sa.h.1.k.weight\", \"blocks.8.sa.h.1.q.weight\", \"blocks.8.sa.h.1.v.weight\", \"blocks.8.sa.h.2.k.weight\", \"blocks.8.sa.h.2.q.weight\", \"blocks.8.sa.h.2.v.weight\", \"blocks.8.sa.h.3.k.weight\", \"blocks.8.sa.h.3.q.weight\", \"blocks.8.sa.h.3.v.weight\", \"blocks.8.sa.h.4.k.weight\", \"blocks.8.sa.h.4.q.weight\", \"blocks.8.sa.h.4.v.weight\", \"blocks.8.sa.h.5.k.weight\", \"blocks.8.sa.h.5.q.weight\", \"blocks.8.sa.h.5.v.weight\", \"blocks.8.sa.h.6.k.weight\", \"blocks.8.sa.h.6.q.weight\", \"blocks.8.sa.h.6.v.weight\", \"blocks.8.sa.h.7.k.weight\", \"blocks.8.sa.h.7.q.weight\", \"blocks.8.sa.h.7.v.weight\", \"blocks.8.sa.h.8.k.weight\", \"blocks.8.sa.h.8.q.weight\", \"blocks.8.sa.h.8.v.weight\", \"blocks.8.sa.h.9.k.weight\", \"blocks.8.sa.h.9.q.weight\", \"blocks.8.sa.h.9.v.weight\", \"blocks.8.sa.h.10.k.weight\", \"blocks.8.sa.h.10.q.weight\", \"blocks.8.sa.h.10.v.weight\", \"blocks.8.sa.h.11.k.weight\", \"blocks.8.sa.h.11.q.weight\", \"blocks.8.sa.h.11.v.weight\", \"blocks.8.sa.p.weight\", \"blocks.8.sa.p.bias\", \"blocks.8.ffwd.net.0.weight\", \"blocks.8.ffwd.net.0.bias\", \"blocks.8.ffwd.net.2.weight\", \"blocks.8.ffwd.net.2.bias\", \"blocks.8.l1.weight\", \"blocks.8.l1.bias\", \"blocks.8.l2.weight\", \"blocks.8.l2.bias\", \"blocks.9.sa.h.0.k.weight\", \"blocks.9.sa.h.0.q.weight\", \"blocks.9.sa.h.0.v.weight\", \"blocks.9.sa.h.1.k.weight\", \"blocks.9.sa.h.1.q.weight\", \"blocks.9.sa.h.1.v.weight\", \"blocks.9.sa.h.2.k.weight\", \"blocks.9.sa.h.2.q.weight\", \"blocks.9.sa.h.2.v.weight\", \"blocks.9.sa.h.3.k.weight\", \"blocks.9.sa.h.3.q.weight\", \"blocks.9.sa.h.3.v.weight\", \"blocks.9.sa.h.4.k.weight\", \"blocks.9.sa.h.4.q.weight\", \"blocks.9.sa.h.4.v.weight\", \"blocks.9.sa.h.5.k.weight\", \"blocks.9.sa.h.5.q.weight\", \"blocks.9.sa.h.5.v.weight\", \"blocks.9.sa.h.6.k.weight\", \"blocks.9.sa.h.6.q.weight\", \"blocks.9.sa.h.6.v.weight\", \"blocks.9.sa.h.7.k.weight\", \"blocks.9.sa.h.7.q.weight\", \"blocks.9.sa.h.7.v.weight\", \"blocks.9.sa.h.8.k.weight\", \"blocks.9.sa.h.8.q.weight\", \"blocks.9.sa.h.8.v.weight\", \"blocks.9.sa.h.9.k.weight\", \"blocks.9.sa.h.9.q.weight\", \"blocks.9.sa.h.9.v.weight\", \"blocks.9.sa.h.10.k.weight\", \"blocks.9.sa.h.10.q.weight\", \"blocks.9.sa.h.10.v.weight\", \"blocks.9.sa.h.11.k.weight\", \"blocks.9.sa.h.11.q.weight\", \"blocks.9.sa.h.11.v.weight\", \"blocks.9.sa.p.weight\", \"blocks.9.sa.p.bias\", \"blocks.9.ffwd.net.0.weight\", \"blocks.9.ffwd.net.0.bias\", \"blocks.9.ffwd.net.2.weight\", \"blocks.9.ffwd.net.2.bias\", \"blocks.9.l1.weight\", \"blocks.9.l1.bias\", \"blocks.9.l2.weight\", \"blocks.9.l2.bias\", \"blocks.10.sa.h.0.k.weight\", \"blocks.10.sa.h.0.q.weight\", \"blocks.10.sa.h.0.v.weight\", \"blocks.10.sa.h.1.k.weight\", \"blocks.10.sa.h.1.q.weight\", \"blocks.10.sa.h.1.v.weight\", \"blocks.10.sa.h.2.k.weight\", \"blocks.10.sa.h.2.q.weight\", \"blocks.10.sa.h.2.v.weight\", \"blocks.10.sa.h.3.k.weight\", \"blocks.10.sa.h.3.q.weight\", \"blocks.10.sa.h.3.v.weight\", \"blocks.10.sa.h.4.k.weight\", \"blocks.10.sa.h.4.q.weight\", \"blocks.10.sa.h.4.v.weight\", \"blocks.10.sa.h.5.k.weight\", \"blocks.10.sa.h.5.q.weight\", \"blocks.10.sa.h.5.v.weight\", \"blocks.10.sa.h.6.k.weight\", \"blocks.10.sa.h.6.q.weight\", \"blocks.10.sa.h.6.v.weight\", \"blocks.10.sa.h.7.k.weight\", \"blocks.10.sa.h.7.q.weight\", \"blocks.10.sa.h.7.v.weight\", \"blocks.10.sa.h.8.k.weight\", \"blocks.10.sa.h.8.q.weight\", \"blocks.10.sa.h.8.v.weight\", \"blocks.10.sa.h.9.k.weight\", \"blocks.10.sa.h.9.q.weight\", \"blocks.10.sa.h.9.v.weight\", \"blocks.10.sa.h.10.k.weight\", \"blocks.10.sa.h.10.q.weight\", \"blocks.10.sa.h.10.v.weight\", \"blocks.10.sa.h.11.k.weight\", \"blocks.10.sa.h.11.q.weight\", \"blocks.10.sa.h.11.v.weight\", \"blocks.10.sa.p.weight\", \"blocks.10.sa.p.bias\", \"blocks.10.ffwd.net.0.weight\", \"blocks.10.ffwd.net.0.bias\", \"blocks.10.ffwd.net.2.weight\", \"blocks.10.ffwd.net.2.bias\", \"blocks.10.l1.weight\", \"blocks.10.l1.bias\", \"blocks.10.l2.weight\", \"blocks.10.l2.bias\", \"blocks.11.sa.h.0.k.weight\", \"blocks.11.sa.h.0.q.weight\", \"blocks.11.sa.h.0.v.weight\", \"blocks.11.sa.h.1.k.weight\", \"blocks.11.sa.h.1.q.weight\", \"blocks.11.sa.h.1.v.weight\", \"blocks.11.sa.h.2.k.weight\", \"blocks.11.sa.h.2.q.weight\", \"blocks.11.sa.h.2.v.weight\", \"blocks.11.sa.h.3.k.weight\", \"blocks.11.sa.h.3.q.weight\", \"blocks.11.sa.h.3.v.weight\", \"blocks.11.sa.h.4.k.weight\", \"blocks.11.sa.h.4.q.weight\", \"blocks.11.sa.h.4.v.weight\", \"blocks.11.sa.h.5.k.weight\", \"blocks.11.sa.h.5.q.weight\", \"blocks.11.sa.h.5.v.weight\", \"blocks.11.sa.h.6.k.weight\", \"blocks.11.sa.h.6.q.weight\", \"blocks.11.sa.h.6.v.weight\", \"blocks.11.sa.h.7.k.weight\", \"blocks.11.sa.h.7.q.weight\", \"blocks.11.sa.h.7.v.weight\", \"blocks.11.sa.h.8.k.weight\", \"blocks.11.sa.h.8.q.weight\", \"blocks.11.sa.h.8.v.weight\", \"blocks.11.sa.h.9.k.weight\", \"blocks.11.sa.h.9.q.weight\", \"blocks.11.sa.h.9.v.weight\", \"blocks.11.sa.h.10.k.weight\", \"blocks.11.sa.h.10.q.weight\", \"blocks.11.sa.h.10.v.weight\", \"blocks.11.sa.h.11.k.weight\", \"blocks.11.sa.h.11.q.weight\", \"blocks.11.sa.h.11.v.weight\", \"blocks.11.sa.p.weight\", \"blocks.11.sa.p.bias\", \"blocks.11.ffwd.net.0.weight\", \"blocks.11.ffwd.net.0.bias\", \"blocks.11.ffwd.net.2.weight\", \"blocks.11.ffwd.net.2.bias\", \"blocks.11.l1.weight\", \"blocks.11.l1.bias\", \"blocks.11.l2.weight\", \"blocks.11.l2.bias\", \"ln_f.weight\", \"ln_f.bias\", \"lm_head.bias\". \n\tUnexpected key(s) in state_dict: \"transformer.wte.weight\", \"transformer.wpe.weight\", \"transformer.h.0.ln_1.weight\", \"transformer.h.0.ln_1.bias\", \"transformer.h.0.attn.bias\", \"transformer.h.0.attn.c_attn.weight\", \"transformer.h.0.attn.c_attn.bias\", \"transformer.h.0.attn.c_proj.weight\", \"transformer.h.0.attn.c_proj.bias\", \"transformer.h.0.ln_2.weight\", \"transformer.h.0.ln_2.bias\", \"transformer.h.0.mlp.c_fc.weight\", \"transformer.h.0.mlp.c_fc.bias\", \"transformer.h.0.mlp.c_proj.weight\", \"transformer.h.0.mlp.c_proj.bias\", \"transformer.h.1.ln_1.weight\", \"transformer.h.1.ln_1.bias\", \"transformer.h.1.attn.bias\", \"transformer.h.1.attn.c_attn.weight\", \"transformer.h.1.attn.c_attn.bias\", \"transformer.h.1.attn.c_proj.weight\", \"transformer.h.1.attn.c_proj.bias\", \"transformer.h.1.ln_2.weight\", \"transformer.h.1.ln_2.bias\", \"transformer.h.1.mlp.c_fc.weight\", \"transformer.h.1.mlp.c_fc.bias\", \"transformer.h.1.mlp.c_proj.weight\", \"transformer.h.1.mlp.c_proj.bias\", \"transformer.h.2.ln_1.weight\", \"transformer.h.2.ln_1.bias\", \"transformer.h.2.attn.bias\", \"transformer.h.2.attn.c_attn.weight\", \"transformer.h.2.attn.c_attn.bias\", \"transformer.h.2.attn.c_proj.weight\", \"transformer.h.2.attn.c_proj.bias\", \"transformer.h.2.ln_2.weight\", \"transformer.h.2.ln_2.bias\", \"transformer.h.2.mlp.c_fc.weight\", \"transformer.h.2.mlp.c_fc.bias\", \"transformer.h.2.mlp.c_proj.weight\", \"transformer.h.2.mlp.c_proj.bias\", \"transformer.h.3.ln_1.weight\", \"transformer.h.3.ln_1.bias\", \"transformer.h.3.attn.bias\", \"transformer.h.3.attn.c_attn.weight\", \"transformer.h.3.attn.c_attn.bias\", \"transformer.h.3.attn.c_proj.weight\", \"transformer.h.3.attn.c_proj.bias\", \"transformer.h.3.ln_2.weight\", \"transformer.h.3.ln_2.bias\", \"transformer.h.3.mlp.c_fc.weight\", \"transformer.h.3.mlp.c_fc.bias\", \"transformer.h.3.mlp.c_proj.weight\", \"transformer.h.3.mlp.c_proj.bias\", \"transformer.h.4.ln_1.weight\", \"transformer.h.4.ln_1.bias\", \"transformer.h.4.attn.bias\", \"transformer.h.4.attn.c_attn.weight\", \"transformer.h.4.attn.c_attn.bias\", \"transformer.h.4.attn.c_proj.weight\", \"transformer.h.4.attn.c_proj.bias\", \"transformer.h.4.ln_2.weight\", \"transformer.h.4.ln_2.bias\", \"transformer.h.4.mlp.c_fc.weight\", \"transformer.h.4.mlp.c_fc.bias\", \"transformer.h.4.mlp.c_proj.weight\", \"transformer.h.4.mlp.c_proj.bias\", \"transformer.h.5.ln_1.weight\", \"transformer.h.5.ln_1.bias\", \"transformer.h.5.attn.bias\", \"transformer.h.5.attn.c_attn.weight\", \"transformer.h.5.attn.c_attn.bias\", \"transformer.h.5.attn.c_proj.weight\", \"transformer.h.5.attn.c_proj.bias\", \"transformer.h.5.ln_2.weight\", \"transformer.h.5.ln_2.bias\", \"transformer.h.5.mlp.c_fc.weight\", \"transformer.h.5.mlp.c_fc.bias\", \"transformer.h.5.mlp.c_proj.weight\", \"transformer.h.5.mlp.c_proj.bias\", \"transformer.h.6.ln_1.weight\", \"transformer.h.6.ln_1.bias\", \"transformer.h.6.attn.bias\", \"transformer.h.6.attn.c_attn.weight\", \"transformer.h.6.attn.c_attn.bias\", \"transformer.h.6.attn.c_proj.weight\", \"transformer.h.6.attn.c_proj.bias\", \"transformer.h.6.ln_2.weight\", \"transformer.h.6.ln_2.bias\", \"transformer.h.6.mlp.c_fc.weight\", \"transformer.h.6.mlp.c_fc.bias\", \"transformer.h.6.mlp.c_proj.weight\", \"transformer.h.6.mlp.c_proj.bias\", \"transformer.h.7.ln_1.weight\", \"transformer.h.7.ln_1.bias\", \"transformer.h.7.attn.bias\", \"transformer.h.7.attn.c_attn.weight\", \"transformer.h.7.attn.c_attn.bias\", \"transformer.h.7.attn.c_proj.weight\", \"transformer.h.7.attn.c_proj.bias\", \"transformer.h.7.ln_2.weight\", \"transformer.h.7.ln_2.bias\", \"transformer.h.7.mlp.c_fc.weight\", \"transformer.h.7.mlp.c_fc.bias\", \"transformer.h.7.mlp.c_proj.weight\", \"transformer.h.7.mlp.c_proj.bias\", \"transformer.ln_f.weight\", \"transformer.ln_f.bias\". \n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([99, 512]) from checkpoint, the shape in current model is torch.Size([5000, 768]).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1793593887.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Weights Loaded Successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2629\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2630\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GPT:\n\tMissing key(s) in state_dict: \"te.weight\", \"pe.weight\", \"blocks.0.sa.h.0.k.weight\", \"blocks.0.sa.h.0.q.weight\", \"blocks.0.sa.h.0.v.weight\", \"blocks.0.sa.h.1.k.weight\", \"blocks.0.sa.h.1.q.weight\", \"blocks.0.sa.h.1.v.weight\", \"blocks.0.sa.h.2.k.weight\", \"blocks.0.sa.h.2.q.weight\", \"blocks.0.sa.h.2.v.weight\", \"blocks.0.sa.h.3.k.weight\", \"blocks.0.sa.h.3.q.weight\", \"blocks.0.sa.h.3.v.weight\", \"blocks.0.sa.h.4.k.weight\", \"blocks.0.sa.h.4.q.weight\", \"blocks.0.sa.h.4.v.weight\", \"blocks.0.sa.h.5.k.weight\", \"blocks.0.sa.h.5.q.weight\", \"blocks.0.sa.h.5.v.weight\", \"blocks.0.sa.h.6.k.weight\", \"blocks.0.sa.h.6.q.weight\", \"blocks.0.sa.h.6.v.weight\", \"blocks.0.sa.h.7.k.weight\", \"blocks.0.sa.h.7.q.weight\", \"blocks.0.sa.h.7.v.weight\", \"blocks.0.sa.h.8.k.weight\", \"blocks.0.sa.h.8.q.weight\", \"blocks.0.sa.h.8.v.weight\", \"blocks.0.sa.h.9.k.weight\", \"blocks.0.sa.h.9.q.weight\", \"blocks.0.sa.h.9.v.weight\", \"blocks.0.sa.h.10.k.weight\", \"blocks.0.sa.h.10.q.weight\", \"blocks.0.sa.h.10.v.weight\", \"blocks.0.sa.h.11.k.weight\", \"blocks.0.sa.h.11.q.weight\", \"blocks.0.sa.h.11.v.weight\", \"blocks.0.sa.p.weight\", \"blocks.0.sa.p.bias\", \"blocks.0.ffwd.net.0.weight\", \"blocks.0.ffwd.net.0.bias\", \"blocks.0.ffwd.net.2.weight\", \"blocks.0.ffwd.net.2.bias\", \"blocks.0.l1.weight\", \"blocks.0.l1.bias\", \"blocks.0.l2.weight\", \"blocks.0.l2.bias\", \"blocks.1.sa.h.0.k.weight\", \"blocks.1.sa.h.0.q.weight\", \"blocks.1.sa.h.0.v.weight\", \"blocks.1.sa.h.1.k.weight\", \"blocks.1.sa.h.1.q.weight\", \"blocks.1.sa.h.1.v.weight\", \"blocks.1.sa...\n\tUnexpected key(s) in state_dict: \"transformer.wte.weight\", \"transformer.wpe.weight\", \"transformer.h.0.ln_1.weight\", \"transformer.h.0.ln_1.bias\", \"transformer.h.0.attn.bias\", \"transformer.h.0.attn.c_attn.weight\", \"transformer.h.0.attn.c_attn.bias\", \"transformer.h.0.attn.c_proj.weight\", \"transformer.h.0.attn.c_proj.bias\", \"transformer.h.0.ln_2.weight\", \"transformer.h.0.ln_2.bias\", \"transformer.h.0.mlp.c_fc.weight\", \"transformer.h.0.mlp.c_fc.bias\", \"transformer.h.0.mlp.c_proj.weight\", \"transformer.h.0.mlp.c_proj.bias\", \"transformer.h.1.ln_1.weight\", \"transformer.h.1.ln_1.bias\", \"transformer.h.1.attn.bias\", \"transformer.h.1.attn.c_attn.weight\", \"transformer.h.1.attn.c_attn.bias\", \"transformer.h.1.attn.c_proj.weight\", \"transformer.h.1.attn.c_proj.bias\", \"transformer.h.1.ln_2.weight\", \"transformer.h.1.ln_2.bias\", \"transformer.h.1.mlp.c_fc.weight\", \"transformer.h.1.mlp.c_fc.bias\", \"transformer.h.1.mlp.c_proj.weight\", \"transformer.h.1.mlp.c_proj.bias\", \"transformer.h.2.ln_1.weight\", \"transformer.h.2.ln_1.bias\", \"transformer.h.2.attn.bias\", \"transformer.h.2.attn.c_attn.weight\", \"transformer.h.2.attn.c_attn.bias\", \"transformer.h.2.attn.c_proj.weight\", \"transformer.h.2.attn.c_proj.bias\", \"transformer.h.2.ln_2.weight\", \"transformer.h.2.ln_2.bias\", \"transformer.h.2.mlp.c_fc.weight\", \"transformer.h.2.mlp.c_fc.bias\", \"transformer.h.2.mlp.c_proj.weight\", \"transformer.h.2.mlp.c_proj.bias\", \"transformer.h.3.ln_1.weight\", \"transformer.h.3.ln_1.bias\", \"transformer.h.3.attn.bias\", \"transforme...\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([99, 512]) from checkpoint, the shape in current model is torch.Size([5000, 768]).","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1793593887.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   Attempting prefix fix...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mnew_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'module.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Weights Loaded (with prefix fix)!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2629\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2630\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2631\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GPT:\n\tMissing key(s) in state_dict: \"te.weight\", \"pe.weight\", \"blocks.0.sa.h.0.k.weight\", \"blocks.0.sa.h.0.q.weight\", \"blocks.0.sa.h.0.v.weight\", \"blocks.0.sa.h.1.k.weight\", \"blocks.0.sa.h.1.q.weight\", \"blocks.0.sa.h.1.v.weight\", \"blocks.0.sa.h.2.k.weight\", \"blocks.0.sa.h.2.q.weight\", \"blocks.0.sa.h.2.v.weight\", \"blocks.0.sa.h.3.k.weight\", \"blocks.0.sa.h.3.q.weight\", \"blocks.0.sa.h.3.v.weight\", \"blocks.0.sa.h.4.k.weight\", \"blocks.0.sa.h.4.q.weight\", \"blocks.0.sa.h.4.v.weight\", \"blocks.0.sa.h.5.k.weight\", \"blocks.0.sa.h.5.q.weight\", \"blocks.0.sa.h.5.v.weight\", \"blocks.0.sa.h.6.k.weight\", \"blocks.0.sa.h.6.q.weight\", \"blocks.0.sa.h.6.v.weight\", \"blocks.0.sa.h.7.k.weight\", \"blocks.0.sa.h.7.q.weight\", \"blocks.0.sa.h.7.v.weight\", \"blocks.0.sa.h.8.k.weight\", \"blocks.0.sa.h.8.q.weight\", \"blocks.0.sa.h.8.v.weight\", \"blocks.0.sa.h.9.k.weight\", \"blocks.0.sa.h.9.q.weight\", \"blocks.0.sa.h.9.v.weight\", \"blocks.0.sa.h.10.k.weight\", \"blocks.0.sa.h.10.q.weight\", \"blocks.0.sa.h.10.v.weight\", \"blocks.0.sa.h.11.k.weight\", \"blocks.0.sa.h.11.q.weight\", \"blocks.0.sa.h.11.v.weight\", \"blocks.0.sa.p.weight\", \"blocks.0.sa.p.bias\", \"blocks.0.ffwd.net.0.weight\", \"blocks.0.ffwd.net.0.bias\", \"blocks.0.ffwd.net.2.weight\", \"blocks.0.ffwd.net.2.bias\", \"blocks.0.l1.weight\", \"blocks.0.l1.bias\", \"blocks.0.l2.weight\", \"blocks.0.l2.bias\", \"blocks.1.sa.h.0.k.weight\", \"blocks.1.sa.h.0.q.weight\", \"blocks.1.sa.h.0.v.weight\", \"blocks.1.sa.h.1.k.weight\", \"blocks.1.sa.h.1.q.weight\", \"blocks.1.sa.h.1.v.weight\", \"blocks.1.sa...\n\tUnexpected key(s) in state_dict: \"transformer.wte.weight\", \"transformer.wpe.weight\", \"transformer.h.0.ln_1.weight\", \"transformer.h.0.ln_1.bias\", \"transformer.h.0.attn.bias\", \"transformer.h.0.attn.c_attn.weight\", \"transformer.h.0.attn.c_attn.bias\", \"transformer.h.0.attn.c_proj.weight\", \"transformer.h.0.attn.c_proj.bias\", \"transformer.h.0.ln_2.weight\", \"transformer.h.0.ln_2.bias\", \"transformer.h.0.mlp.c_fc.weight\", \"transformer.h.0.mlp.c_fc.bias\", \"transformer.h.0.mlp.c_proj.weight\", \"transformer.h.0.mlp.c_proj.bias\", \"transformer.h.1.ln_1.weight\", \"transformer.h.1.ln_1.bias\", \"transformer.h.1.attn.bias\", \"transformer.h.1.attn.c_attn.weight\", \"transformer.h.1.attn.c_attn.bias\", \"transformer.h.1.attn.c_proj.weight\", \"transformer.h.1.attn.c_proj.bias\", \"transformer.h.1.ln_2.weight\", \"transformer.h.1.ln_2.bias\", \"transformer.h.1.mlp.c_fc.weight\", \"transformer.h.1.mlp.c_fc.bias\", \"transformer.h.1.mlp.c_proj.weight\", \"transformer.h.1.mlp.c_proj.bias\", \"transformer.h.2.ln_1.weight\", \"transformer.h.2.ln_1.bias\", \"transformer.h.2.attn.bias\", \"transformer.h.2.attn.c_attn.weight\", \"transformer.h.2.attn.c_attn.bias\", \"transformer.h.2.attn.c_proj.weight\", \"transformer.h.2.attn.c_proj.bias\", \"transformer.h.2.ln_2.weight\", \"transformer.h.2.ln_2.bias\", \"transformer.h.2.mlp.c_fc.weight\", \"transformer.h.2.mlp.c_fc.bias\", \"transformer.h.2.mlp.c_proj.weight\", \"transformer.h.2.mlp.c_proj.bias\", \"transformer.h.3.ln_1.weight\", \"transformer.h.3.ln_1.bias\", \"transformer.h.3.attn.bias\", \"transforme...\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([99, 512]) from checkpoint, the shape in current model is torch.Size([5000, 768])."]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import numpy as np\n","from tokenizers import Tokenizer\n","from music21 import converter\n","from google.colab import drive\n","\n","# ==========================================\n","# 1. SETUP\n","# ==========================================\n","print(\"üöë Starting Final Music Generator...\")\n","drive.mount('/content/drive')\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Define Paths\n","LOCAL_DATA = '/content/local_data'\n","OUTPUT_ABC = '/content/generated_music_abc'\n","OUTPUT_MIDI = '/content/generated_music_midi'\n","os.makedirs(OUTPUT_ABC, exist_ok=True)\n","os.makedirs(OUTPUT_MIDI, exist_ok=True)\n","\n","# Config for Speed & Stability\n","BLOCK_SIZE = 256\n","BATCH_SIZE = 64\n","VOCAB_SIZE = 5000\n","# We use a \"Medium-Small\" config that learns faster than Large\n","config = {'n_layer': 6, 'n_head': 6, 'n_embd': 384}\n","\n","# ==========================================\n","# 2. MODEL DEFINITION (Fixed Loss Logic)\n","# ==========================================\n","class Head(nn.Module):\n","    def __init__(self, hs, ne):\n","        super().__init__()\n","        self.k = nn.Linear(ne, hs, bias=False); self.q = nn.Linear(ne, hs, bias=False)\n","        self.v = nn.Linear(ne, hs, bias=False); self.tril = torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)).to(DEVICE)\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        w = self.q(x) @ self.k(x).transpose(-2,-1) * C**-0.5\n","        w = w.masked_fill(self.tril[:T,:T]==0, float('-inf'))\n","        return F.softmax(w, -1) @ self.v(x)\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, n, hs, ne):\n","        super().__init__()\n","        self.h = nn.ModuleList([Head(hs, ne) for _ in range(n)]); self.p = nn.Linear(ne, ne)\n","    def forward(self, x): return self.p(torch.cat([h(x) for h in self.h], dim=-1))\n","\n","class FeedFoward(nn.Module):\n","    def __init__(self, ne):\n","        super().__init__()\n","        self.net = nn.Sequential(nn.Linear(ne, 4*ne), nn.ReLU(), nn.Linear(4*ne, ne))\n","    def forward(self, x): return self.net(x)\n","\n","class Block(nn.Module):\n","    def __init__(self, ne, nh):\n","        super().__init__()\n","        self.sa = MultiHeadAttention(nh, ne//nh, ne); self.ffwd = FeedFoward(ne)\n","        self.l1 = nn.LayerNorm(ne); self.l2 = nn.LayerNorm(ne)\n","    def forward(self, x): return x + self.sa(self.l1(x)) + self.ffwd(self.l2(x))\n","\n","class GPT(nn.Module):\n","    def __init__(self, c):\n","        super().__init__()\n","        self.te = nn.Embedding(VOCAB_SIZE, c['n_embd']); self.pe = nn.Embedding(BLOCK_SIZE, c['n_embd'])\n","        self.blocks = nn.Sequential(*[Block(c['n_embd'], c['n_head']) for _ in range(c['n_layer'])])\n","        self.ln_f = nn.LayerNorm(c['n_embd']); self.lm_head = nn.Linear(c['n_embd'], VOCAB_SIZE)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","        x = self.te(idx) + self.pe(torch.arange(T, device=DEVICE))\n","        x = self.ln_f(self.blocks(x))\n","        logits = self.lm_head(x)\n","\n","        loss = None\n","        if targets is not None:\n","            # Flatten for cross_entropy\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","# ==========================================\n","# 3. TRAINING (800 Steps)\n","# ==========================================\n","model = GPT(config).to(DEVICE)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n","\n","# Load Data\n","if not os.path.exists(os.path.join(LOCAL_DATA, 'train.bin')):\n","    print(\"üîÑ Fetching data from Drive...\")\n","    import shutil\n","    shutil.copy('/content/drive/MyDrive/NYU_ML_Project/Data/processed_v4/train.bin', os.path.join(LOCAL_DATA, 'train.bin'))\n","    shutil.copy('/content/drive/MyDrive/NYU_ML_Project/Data/processed_v4/music_bpe.json', os.path.join(LOCAL_DATA, 'music_bpe.json'))\n","\n","data = np.memmap(os.path.join(LOCAL_DATA, 'train.bin'), dtype=np.uint16, mode='r')\n","\n","def get_batch():\n","    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n","    x = torch.stack([torch.from_numpy((data[i:i+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n","    y = torch.stack([torch.from_numpy((data[i+1:i+1+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n","    return x.to(DEVICE), y.to(DEVICE)\n","\n","print(\"üöÄ Training Generator (Wait ~8 mins)...\")\n","model.train()\n","for i in range(800):\n","    xb, yb = get_batch()\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","    if i % 100 == 0: print(f\"   Step {i}/800 | Loss: {loss.item():.4f}\", end='\\r')\n","\n","print(f\"\\n‚úÖ Training Done. Final Loss: {loss.item():.4f}\")\n","\n","# ==========================================\n","# 4. GENERATION & CONVERSION\n","# ==========================================\n","print(\"\\nüéπ Generating 5 Samples...\")\n","tokenizer = Tokenizer.from_file(os.path.join(LOCAL_DATA, 'music_bpe.json'))\n","model.eval()\n","\n","for i in range(5):\n","    print(f\"   Processing sample_{i+1}...\", end='\\r')\n","    ctx = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n","\n","    with torch.no_grad():\n","        for _ in range(500):\n","            cond = ctx[:, -BLOCK_SIZE:]\n","            logits, _ = model(cond)\n","            # Sample with slight temperature for variety\n","            logits = logits[:, -1, :] / 1.0\n","            probs = F.softmax(logits, dim=-1)\n","            ctx = torch.cat((ctx, torch.multinomial(probs, 1)), dim=1)\n","\n","    # Save ABC\n","    abc_str = tokenizer.decode(ctx[0].tolist())\n","    abc_path = os.path.join(OUTPUT_ABC, f\"sample_{i+1}.abc\")\n","    with open(abc_path, 'w') as f: f.write(abc_str)\n","\n","    # Convert to MIDI\n","    try:\n","        s = converter.parse(abc_path)\n","        midi_path = os.path.join(OUTPUT_MIDI, f\"sample_{i+1}.mid\")\n","        s.write('midi', fp=midi_path)\n","    except:\n","        pass\n","\n","print(f\"\\n\\nüéâ DONE! Go to folder '{OUTPUT_MIDI}' to download your playable music.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"t3HGp0yL1ILM","executionInfo":{"status":"error","timestamp":1765749131390,"user_tz":300,"elapsed":31821,"user":{"displayName":"Pranjal Mishra","userId":"02221036449147810179"}},"outputId":"939e7112-759a-4ef9-84a4-7c1476374c9a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["üöë Starting Final Music Generator...\n","Mounted at /content/drive\n","üîÑ Fetching data from Drive...\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/local_data/train.bin'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3021315331.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üîÑ Fetching data from Drive...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/NYU_ML_Project/Data/processed_v4/train.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/NYU_ML_Project/Data/processed_v4/music_bpe.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'music_bpe.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/local_data/train.bin'"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOFSRBpfQEZlv9i7gAMEE9u"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}